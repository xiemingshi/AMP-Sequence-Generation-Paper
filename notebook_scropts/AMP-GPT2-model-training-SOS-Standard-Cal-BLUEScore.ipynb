{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656682a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3276f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose train mode\n",
    "global mode\n",
    "# mode = 'pretrain'\n",
    "mode = 'finetune'\n",
    "# mode = 'else'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6066b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizer(name_or_path='', vocab_size=23, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]'})\n"
     ]
    }
   ],
   "source": [
    "# device and tokenizer\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer('./vocab_file/vocab.json', './vocab_file/merges.txt')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "if mode == 'pretrain':\n",
    "    tokenizer.save_pretrained('./save_model/pretrain_model/pretrained-gpt-10-64raw-50epochs') # when pretrain model\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eff80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        if mode == 'finetune':\n",
    "#             with open('./data/ADP3_amp.txt') as f:  # when finetune\n",
    "            with open('./data/ADP3_amp.txt') as f:  # when finetune\n",
    "                lines = f.readlines()\n",
    "        elif mode == 'pretrain':\n",
    "            with open('./data/pretrain_data/uniprot10-63.txt') as f:  # when pretrain model \n",
    "                lines = f.readlines()\n",
    "        else:\n",
    "            print('train mode error')\n",
    "            with open('./data/ADP3_amp.txt') as f:\n",
    "                lines = f.readlines()\n",
    "        lines = [i.strip() for i in lines]\n",
    "\n",
    "        self.lines = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.lines[i]\n",
    "\n",
    "\n",
    "global val_split\n",
    "if mode == 'pretrain':\n",
    "    val_split = 0.01\n",
    "elif mode =='finetune':\n",
    "    val_split = 0.1\n",
    "else:\n",
    "    val_split = 0.4\n",
    "\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(val_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = Data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = Data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "def collate_fn(data):\n",
    "    data = tokenizer.batch_encode_plus(data,\n",
    "                                       padding=True,\n",
    "                                       truncation=True,\n",
    "                                       max_length=48,\n",
    "                                       return_tensors='pt')\n",
    "\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32, \n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32, \n",
    "    sampler=val_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,)\n",
    "\n",
    "# for i, data in enumerate(val_loader):\n",
    "    \n",
    "\n",
    "#     for k, v in data.items():\n",
    "#         print(k, v.shape, v)\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de835ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GPT model\n",
    "\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(n_layer=12, \n",
    "                           n_head=12,\n",
    "                           n_embd=768)\n",
    "\n",
    "# print(configuration)\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "if mode == 'pretrain':\n",
    "    model = GPT2LMHeadModel(configuration)  # when pretrain model\n",
    "elif mode == 'finetune':\n",
    "    model = GPT2LMHeadModel.from_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64washed-30epochs')\n",
    "else:\n",
    "    pass\n",
    "#     model = GPT2LMHeadModel.from_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64raw-20epochs/')\n",
    "# model = torch.load('./save_model/pretrained-gpt-10-48-30epochs/pytorch_model.bin')  # pretrain model use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f560aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\",num_classes=23,ignore_index=23)\n",
    "accuracy = accuracy.to(device)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_acc_list =[]\n",
    "val_acc_list = []\n",
    "blue_score_list = []\n",
    "    \n",
    "#训练\n",
    "def train():\n",
    "    global model\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=400,\n",
    "                              num_training_steps=len(train_loader)*epochs,\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    model.train()\n",
    "    print('开始训练')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        val_loss = []\n",
    "        val_accuracy = []\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(**batch_data)\n",
    "            loss = out['loss']\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            \n",
    "            labels = batch_data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "            train_acc = accuracy(out, labels)\n",
    "            train_accuracy.append(train_acc.tolist())\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('train_batch: {:3d}  loss:{:.4f}  accuracy:{:.4f}'\n",
    "                      .format(batch_idx, loss.item(), train_acc.item()))\n",
    "            \n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(**batch_data)\n",
    "            loss = out['loss']\n",
    "            labels = batch_data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "            val_acc = accuracy(out, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            val_accuracy.append(val_acc.tolist())\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('val_batch:   {:3d}  loss:{:.4f}  accuracy:{:.4f}'\n",
    "                      .format(batch_idx, loss.item(), val_acc.item()))\n",
    "            \n",
    "        train_loss_list.append(np.mean(train_loss))\n",
    "        train_acc_list.append(np.mean(train_accuracy))\n",
    "        val_loss_list.append(np.mean(val_loss))\n",
    "        val_acc_list.append(np.mean(val_accuracy))\n",
    "        \n",
    "        train_time = time.time()\n",
    "        print('第{}代训练完成,历时{}秒'.format(epoch+1,train_time-start_time))\n",
    "        print('epoch {} mean training loss:{:.4f}'.format(epoch+1, np.mean(train_loss)))\n",
    "        print('epoch {} mean training accuracy:{:.4f}'.format(epoch+1, np.mean(train_accuracy)))\n",
    "        print('epoch {} mean val loss:{:.4f}'.format(epoch+1, np.mean(val_loss)))\n",
    "        print('epoch {} mean val accuracy:{:.4f} '.format(epoch+1, np.mean(val_accuracy)))\n",
    "        print(' ')\n",
    "        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('训练结束,训练时长：',end_time-start_time, '秒')   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73cb1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "train_batch:   0  loss:1.5708  accuracy:0.1773\n",
      "train_batch:  50  loss:1.9412  accuracy:0.1529\n",
      "train_batch: 100  loss:1.7510  accuracy:0.1672\n",
      "train_batch: 150  loss:1.7228  accuracy:0.1403\n",
      "val_batch:     0  loss:1.7831  accuracy:0.1637\n",
      "第1代训练完成,历时17.8853702545166秒\n",
      "epoch 1 mean training loss:1.7813\n",
      "epoch 1 mean training accuracy:0.1601\n",
      "epoch 1 mean val loss:1.7604\n",
      "epoch 1 mean val accuracy:0.1836 \n",
      " \n",
      "train_batch:   0  loss:1.6970  accuracy:0.2013\n",
      "train_batch:  50  loss:1.6088  accuracy:0.1804\n",
      "train_batch: 100  loss:1.7907  accuracy:0.1988\n",
      "train_batch: 150  loss:1.6859  accuracy:0.1907\n",
      "val_batch:     0  loss:1.6240  accuracy:0.2530\n",
      "第2代训练完成,历时35.07102298736572秒\n",
      "epoch 2 mean training loss:1.6514\n",
      "epoch 2 mean training accuracy:0.1997\n",
      "epoch 2 mean val loss:1.6729\n",
      "epoch 2 mean val accuracy:0.2225 \n",
      " \n",
      "train_batch:   0  loss:1.3336  accuracy:0.2311\n",
      "train_batch:  50  loss:1.4629  accuracy:0.2220\n",
      "train_batch: 100  loss:1.6727  accuracy:0.2095\n",
      "train_batch: 150  loss:1.4565  accuracy:0.2503\n",
      "val_batch:     0  loss:1.6441  accuracy:0.2852\n",
      "第3代训练完成,历时52.325364112854004秒\n",
      "epoch 3 mean training loss:1.5689\n",
      "epoch 3 mean training accuracy:0.2394\n",
      "epoch 3 mean val loss:1.6235\n",
      "epoch 3 mean val accuracy:0.2506 \n",
      " \n",
      "train_batch:   0  loss:1.6539  accuracy:0.2380\n",
      "train_batch:  50  loss:1.6143  accuracy:0.2586\n",
      "train_batch: 100  loss:1.5466  accuracy:0.2022\n",
      "train_batch: 150  loss:1.4787  accuracy:0.2711\n",
      "val_batch:     0  loss:1.6504  accuracy:0.2707\n",
      "第4代训练完成,历时69.6032304763794秒\n",
      "epoch 4 mean training loss:1.5087\n",
      "epoch 4 mean training accuracy:0.2689\n",
      "epoch 4 mean val loss:1.5852\n",
      "epoch 4 mean val accuracy:0.2674 \n",
      " \n",
      "train_batch:   0  loss:1.4692  accuracy:0.3074\n",
      "train_batch:  50  loss:1.6359  accuracy:0.2418\n",
      "train_batch: 100  loss:1.4523  accuracy:0.2849\n",
      "train_batch: 150  loss:1.4645  accuracy:0.2435\n",
      "val_batch:     0  loss:1.5684  accuracy:0.3207\n",
      "第5代训练完成,历时86.90456891059875秒\n",
      "epoch 5 mean training loss:1.4695\n",
      "epoch 5 mean training accuracy:0.2894\n",
      "epoch 5 mean val loss:1.5448\n",
      "epoch 5 mean val accuracy:0.2833 \n",
      " \n",
      "train_batch:   0  loss:1.3485  accuracy:0.2824\n",
      "train_batch:  50  loss:1.3518  accuracy:0.3435\n",
      "train_batch: 100  loss:1.3382  accuracy:0.3157\n",
      "train_batch: 150  loss:1.7078  accuracy:0.2407\n",
      "val_batch:     0  loss:1.6956  accuracy:0.2229\n",
      "第6代训练完成,历时104.23274970054626秒\n",
      "epoch 6 mean training loss:1.4392\n",
      "epoch 6 mean training accuracy:0.3032\n",
      "epoch 6 mean val loss:1.5326\n",
      "epoch 6 mean val accuracy:0.2894 \n",
      " \n",
      "train_batch:   0  loss:1.3826  accuracy:0.3018\n",
      "train_batch:  50  loss:1.3214  accuracy:0.3164\n",
      "train_batch: 100  loss:1.1987  accuracy:0.3864\n",
      "train_batch: 150  loss:1.5267  accuracy:0.2915\n",
      "val_batch:     0  loss:1.3839  accuracy:0.3139\n",
      "第7代训练完成,历时121.54597067832947秒\n",
      "epoch 7 mean training loss:1.4134\n",
      "epoch 7 mean training accuracy:0.3152\n",
      "epoch 7 mean val loss:1.5006\n",
      "epoch 7 mean val accuracy:0.3029 \n",
      " \n",
      "train_batch:   0  loss:1.4307  accuracy:0.2830\n",
      "train_batch:  50  loss:1.4394  accuracy:0.3343\n",
      "train_batch: 100  loss:1.5490  accuracy:0.2937\n",
      "train_batch: 150  loss:1.4821  accuracy:0.2682\n",
      "val_batch:     0  loss:1.5549  accuracy:0.3249\n",
      "第8代训练完成,历时138.86881566047668秒\n",
      "epoch 8 mean training loss:1.3882\n",
      "epoch 8 mean training accuracy:0.3280\n",
      "epoch 8 mean val loss:1.4981\n",
      "epoch 8 mean val accuracy:0.3109 \n",
      " \n",
      "train_batch:   0  loss:1.1521  accuracy:0.4104\n",
      "train_batch:  50  loss:1.5425  accuracy:0.2847\n",
      "train_batch: 100  loss:1.3844  accuracy:0.3607\n",
      "train_batch: 150  loss:1.4243  accuracy:0.3084\n",
      "val_batch:     0  loss:1.1708  accuracy:0.3588\n",
      "第9代训练完成,历时156.18265652656555秒\n",
      "epoch 9 mean training loss:1.3687\n",
      "epoch 9 mean training accuracy:0.3377\n",
      "epoch 9 mean val loss:1.4762\n",
      "epoch 9 mean val accuracy:0.3132 \n",
      " \n",
      "train_batch:   0  loss:1.3354  accuracy:0.3982\n",
      "train_batch:  50  loss:1.3119  accuracy:0.3953\n",
      "train_batch: 100  loss:1.3535  accuracy:0.3689\n",
      "train_batch: 150  loss:1.2739  accuracy:0.3986\n",
      "val_batch:     0  loss:1.4099  accuracy:0.2846\n",
      "第10代训练完成,历时173.5068428516388秒\n",
      "epoch 10 mean training loss:1.3508\n",
      "epoch 10 mean training accuracy:0.3485\n",
      "epoch 10 mean val loss:1.4795\n",
      "epoch 10 mean val accuracy:0.3169 \n",
      " \n",
      "train_batch:   0  loss:1.2998  accuracy:0.3658\n",
      "train_batch:  50  loss:1.5187  accuracy:0.2829\n",
      "train_batch: 100  loss:1.2673  accuracy:0.3838\n",
      "train_batch: 150  loss:1.3255  accuracy:0.3812\n",
      "val_batch:     0  loss:1.5362  accuracy:0.3691\n",
      "第11代训练完成,历时190.8239767551422秒\n",
      "epoch 11 mean training loss:1.3322\n",
      "epoch 11 mean training accuracy:0.3566\n",
      "epoch 11 mean val loss:1.4693\n",
      "epoch 11 mean val accuracy:0.3213 \n",
      " \n",
      "train_batch:   0  loss:1.1517  accuracy:0.3650\n",
      "train_batch:  50  loss:1.1645  accuracy:0.4058\n",
      "train_batch: 100  loss:1.3213  accuracy:0.3624\n",
      "train_batch: 150  loss:0.9724  accuracy:0.4352\n",
      "val_batch:     0  loss:1.2702  accuracy:0.3414\n",
      "第12代训练完成,历时208.16889071464539秒\n",
      "epoch 12 mean training loss:1.3162\n",
      "epoch 12 mean training accuracy:0.3663\n",
      "epoch 12 mean val loss:1.4569\n",
      "epoch 12 mean val accuracy:0.3305 \n",
      " \n",
      "train_batch:   0  loss:1.3658  accuracy:0.3743\n",
      "train_batch:  50  loss:1.2215  accuracy:0.3704\n",
      "train_batch: 100  loss:1.3328  accuracy:0.3565\n",
      "train_batch: 150  loss:1.2336  accuracy:0.3753\n",
      "val_batch:     0  loss:1.3823  accuracy:0.3530\n",
      "第13代训练完成,历时225.61876130104065秒\n",
      "epoch 13 mean training loss:1.3008\n",
      "epoch 13 mean training accuracy:0.3727\n",
      "epoch 13 mean val loss:1.4472\n",
      "epoch 13 mean val accuracy:0.3379 \n",
      " \n",
      "train_batch:   0  loss:1.2344  accuracy:0.4105\n",
      "train_batch:  50  loss:1.3690  accuracy:0.2849\n",
      "train_batch: 100  loss:1.4368  accuracy:0.3219\n",
      "train_batch: 150  loss:1.4584  accuracy:0.3337\n",
      "val_batch:     0  loss:1.2659  accuracy:0.3409\n",
      "第14代训练完成,历时242.95510482788086秒\n",
      "epoch 14 mean training loss:1.2888\n",
      "epoch 14 mean training accuracy:0.3780\n",
      "epoch 14 mean val loss:1.4442\n",
      "epoch 14 mean val accuracy:0.3373 \n",
      " \n",
      "train_batch:   0  loss:1.1611  accuracy:0.3967\n",
      "train_batch:  50  loss:1.4226  accuracy:0.3383\n",
      "train_batch: 100  loss:1.2682  accuracy:0.3564\n",
      "train_batch: 150  loss:1.3402  accuracy:0.3743\n",
      "val_batch:     0  loss:1.4561  accuracy:0.3197\n",
      "第15代训练完成,历时260.28955698013306秒\n",
      "epoch 15 mean training loss:1.2741\n",
      "epoch 15 mean training accuracy:0.3863\n",
      "epoch 15 mean val loss:1.4293\n",
      "epoch 15 mean val accuracy:0.3415 \n",
      " \n",
      "train_batch:   0  loss:1.3997  accuracy:0.3690\n",
      "train_batch:  50  loss:1.2256  accuracy:0.3625\n",
      "train_batch: 100  loss:1.2999  accuracy:0.3980\n",
      "train_batch: 150  loss:1.3125  accuracy:0.3761\n",
      "val_batch:     0  loss:1.4891  accuracy:0.3343\n",
      "第16代训练完成,历时277.6070477962494秒\n",
      "epoch 16 mean training loss:1.2591\n",
      "epoch 16 mean training accuracy:0.3923\n",
      "epoch 16 mean val loss:1.4395\n",
      "epoch 16 mean val accuracy:0.3435 \n",
      " \n",
      "train_batch:   0  loss:0.9889  accuracy:0.4710\n",
      "train_batch:  50  loss:0.9512  accuracy:0.4715\n",
      "train_batch: 100  loss:1.3401  accuracy:0.3565\n",
      "train_batch: 150  loss:1.0892  accuracy:0.4498\n",
      "val_batch:     0  loss:1.3979  accuracy:0.3406\n",
      "第17代训练完成,历时294.91721963882446秒\n",
      "epoch 17 mean training loss:1.2511\n",
      "epoch 17 mean training accuracy:0.3974\n",
      "epoch 17 mean val loss:1.4355\n",
      "epoch 17 mean val accuracy:0.3459 \n",
      " \n",
      "train_batch:   0  loss:1.2331  accuracy:0.4479\n",
      "train_batch:  50  loss:1.0613  accuracy:0.4670\n",
      "train_batch: 100  loss:1.1463  accuracy:0.4474\n",
      "train_batch: 150  loss:1.4259  accuracy:0.3351\n",
      "val_batch:     0  loss:1.5471  accuracy:0.3034\n",
      "第18代训练完成,历时312.2466058731079秒\n",
      "epoch 18 mean training loss:1.2385\n",
      "epoch 18 mean training accuracy:0.4041\n",
      "epoch 18 mean val loss:1.4088\n",
      "epoch 18 mean val accuracy:0.3480 \n",
      " \n",
      "train_batch:   0  loss:1.2186  accuracy:0.4307\n",
      "train_batch:  50  loss:1.3830  accuracy:0.3745\n",
      "train_batch: 100  loss:1.3144  accuracy:0.3815\n",
      "train_batch: 150  loss:1.3731  accuracy:0.3601\n",
      "val_batch:     0  loss:1.5100  accuracy:0.3260\n",
      "第19代训练完成,历时329.5741548538208秒\n",
      "epoch 19 mean training loss:1.2296\n",
      "epoch 19 mean training accuracy:0.4073\n",
      "epoch 19 mean val loss:1.4250\n",
      "epoch 19 mean val accuracy:0.3511 \n",
      " \n",
      "train_batch:   0  loss:1.0587  accuracy:0.4968\n",
      "train_batch:  50  loss:1.3378  accuracy:0.3828\n",
      "train_batch: 100  loss:1.1498  accuracy:0.4551\n",
      "train_batch: 150  loss:1.2580  accuracy:0.3912\n",
      "val_batch:     0  loss:1.4706  accuracy:0.3203\n",
      "第20代训练完成,历时346.90510869026184秒\n",
      "epoch 20 mean training loss:1.2183\n",
      "epoch 20 mean training accuracy:0.4122\n",
      "epoch 20 mean val loss:1.4210\n",
      "epoch 20 mean val accuracy:0.3499 \n",
      " \n",
      "train_batch:   0  loss:1.0898  accuracy:0.3755\n",
      "train_batch:  50  loss:1.2236  accuracy:0.4406\n",
      "train_batch: 100  loss:1.1381  accuracy:0.3669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch: 150  loss:1.2547  accuracy:0.4440\n",
      "val_batch:     0  loss:1.3799  accuracy:0.3662\n",
      "第21代训练完成,历时364.2272231578827秒\n",
      "epoch 21 mean training loss:1.2097\n",
      "epoch 21 mean training accuracy:0.4169\n",
      "epoch 21 mean val loss:1.3955\n",
      "epoch 21 mean val accuracy:0.3590 \n",
      " \n",
      "train_batch:   0  loss:1.3915  accuracy:0.3780\n",
      "train_batch:  50  loss:1.1482  accuracy:0.4672\n",
      "train_batch: 100  loss:1.1568  accuracy:0.4468\n",
      "train_batch: 150  loss:1.1807  accuracy:0.4524\n",
      "val_batch:     0  loss:1.2567  accuracy:0.3902\n",
      "第22代训练完成,历时381.5475811958313秒\n",
      "epoch 22 mean training loss:1.2005\n",
      "epoch 22 mean training accuracy:0.4211\n",
      "epoch 22 mean val loss:1.4063\n",
      "epoch 22 mean val accuracy:0.3627 \n",
      " \n",
      "train_batch:   0  loss:1.1230  accuracy:0.4377\n",
      "train_batch:  50  loss:1.1583  accuracy:0.4691\n",
      "train_batch: 100  loss:1.2165  accuracy:0.4002\n",
      "train_batch: 150  loss:1.2302  accuracy:0.4061\n",
      "val_batch:     0  loss:1.4588  accuracy:0.3344\n",
      "第23代训练完成,历时398.86718821525574秒\n",
      "epoch 23 mean training loss:1.1917\n",
      "epoch 23 mean training accuracy:0.4258\n",
      "epoch 23 mean val loss:1.4069\n",
      "epoch 23 mean val accuracy:0.3549 \n",
      " \n",
      "train_batch:   0  loss:1.2716  accuracy:0.3746\n",
      "train_batch:  50  loss:1.4706  accuracy:0.3804\n",
      "train_batch: 100  loss:1.1922  accuracy:0.4539\n",
      "train_batch: 150  loss:1.1663  accuracy:0.3865\n",
      "val_batch:     0  loss:1.5687  accuracy:0.3353\n",
      "第24代训练完成,历时416.1822190284729秒\n",
      "epoch 24 mean training loss:1.1863\n",
      "epoch 24 mean training accuracy:0.4277\n",
      "epoch 24 mean val loss:1.4036\n",
      "epoch 24 mean val accuracy:0.3601 \n",
      " \n",
      "train_batch:   0  loss:1.0915  accuracy:0.4551\n",
      "train_batch:  50  loss:1.0899  accuracy:0.4203\n",
      "train_batch: 100  loss:1.1498  accuracy:0.4634\n",
      "train_batch: 150  loss:1.1282  accuracy:0.4995\n",
      "val_batch:     0  loss:1.5034  accuracy:0.3596\n",
      "第25代训练完成,历时433.50068283081055秒\n",
      "epoch 25 mean training loss:1.1785\n",
      "epoch 25 mean training accuracy:0.4312\n",
      "epoch 25 mean val loss:1.4043\n",
      "epoch 25 mean val accuracy:0.3593 \n",
      " \n",
      "train_batch:   0  loss:0.9498  accuracy:0.4927\n",
      "train_batch:  50  loss:1.3896  accuracy:0.3464\n",
      "train_batch: 100  loss:1.0053  accuracy:0.5241\n",
      "train_batch: 150  loss:0.9291  accuracy:0.4572\n",
      "val_batch:     0  loss:1.4228  accuracy:0.3796\n",
      "第26代训练完成,历时450.8229262828827秒\n",
      "epoch 26 mean training loss:1.1687\n",
      "epoch 26 mean training accuracy:0.4361\n",
      "epoch 26 mean val loss:1.4043\n",
      "epoch 26 mean val accuracy:0.3629 \n",
      " \n",
      "train_batch:   0  loss:1.0217  accuracy:0.4597\n",
      "train_batch:  50  loss:1.1493  accuracy:0.4662\n",
      "train_batch: 100  loss:1.1045  accuracy:0.4397\n",
      "train_batch: 150  loss:1.2181  accuracy:0.4200\n",
      "val_batch:     0  loss:1.2895  accuracy:0.4372\n",
      "第27代训练完成,历时468.1346321105957秒\n",
      "epoch 27 mean training loss:1.1621\n",
      "epoch 27 mean training accuracy:0.4403\n",
      "epoch 27 mean val loss:1.4034\n",
      "epoch 27 mean val accuracy:0.3631 \n",
      " \n",
      "train_batch:   0  loss:1.0781  accuracy:0.4254\n",
      "train_batch:  50  loss:1.0413  accuracy:0.4657\n",
      "train_batch: 100  loss:1.4656  accuracy:0.3678\n",
      "train_batch: 150  loss:1.0701  accuracy:0.4411\n",
      "val_batch:     0  loss:1.6066  accuracy:0.3340\n",
      "第28代训练完成,历时485.4532380104065秒\n",
      "epoch 28 mean training loss:1.1579\n",
      "epoch 28 mean training accuracy:0.4426\n",
      "epoch 28 mean val loss:1.4026\n",
      "epoch 28 mean val accuracy:0.3637 \n",
      " \n",
      "train_batch:   0  loss:1.2458  accuracy:0.4103\n",
      "train_batch:  50  loss:1.3642  accuracy:0.3960\n",
      "train_batch: 100  loss:1.0852  accuracy:0.4810\n",
      "train_batch: 150  loss:1.2271  accuracy:0.4095\n",
      "val_batch:     0  loss:1.5265  accuracy:0.3559\n",
      "第29代训练完成,历时502.88809466362秒\n",
      "epoch 29 mean training loss:1.1504\n",
      "epoch 29 mean training accuracy:0.4443\n",
      "epoch 29 mean val loss:1.4125\n",
      "epoch 29 mean val accuracy:0.3625 \n",
      " \n",
      "train_batch:   0  loss:1.1608  accuracy:0.4200\n",
      "train_batch:  50  loss:1.2089  accuracy:0.3964\n",
      "train_batch: 100  loss:1.1777  accuracy:0.4201\n",
      "train_batch: 150  loss:1.2410  accuracy:0.3690\n",
      "val_batch:     0  loss:1.2730  accuracy:0.3916\n",
      "第30代训练完成,历时520.2080972194672秒\n",
      "epoch 30 mean training loss:1.1428\n",
      "epoch 30 mean training accuracy:0.4481\n",
      "epoch 30 mean val loss:1.3874\n",
      "epoch 30 mean val accuracy:0.3699 \n",
      " \n",
      "train_batch:   0  loss:1.1223  accuracy:0.4544\n",
      "train_batch:  50  loss:1.0151  accuracy:0.5243\n",
      "train_batch: 100  loss:1.0549  accuracy:0.4742\n",
      "train_batch: 150  loss:1.0207  accuracy:0.4669\n",
      "val_batch:     0  loss:1.2990  accuracy:0.3862\n",
      "第31代训练完成,历时537.5315911769867秒\n",
      "epoch 31 mean training loss:1.1394\n",
      "epoch 31 mean training accuracy:0.4502\n",
      "epoch 31 mean val loss:1.3902\n",
      "epoch 31 mean val accuracy:0.3703 \n",
      " \n",
      "train_batch:   0  loss:0.9738  accuracy:0.5011\n",
      "train_batch:  50  loss:1.0317  accuracy:0.4594\n",
      "train_batch: 100  loss:1.2426  accuracy:0.4700\n",
      "train_batch: 150  loss:0.9902  accuracy:0.4988\n",
      "val_batch:     0  loss:1.2707  accuracy:0.4135\n",
      "第32代训练完成,历时554.848955154419秒\n",
      "epoch 32 mean training loss:1.1341\n",
      "epoch 32 mean training accuracy:0.4530\n",
      "epoch 32 mean val loss:1.3963\n",
      "epoch 32 mean val accuracy:0.3692 \n",
      " \n",
      "train_batch:   0  loss:1.2007  accuracy:0.4202\n",
      "train_batch:  50  loss:1.0520  accuracy:0.4957\n",
      "train_batch: 100  loss:1.0478  accuracy:0.5133\n",
      "train_batch: 150  loss:1.2334  accuracy:0.3968\n",
      "val_batch:     0  loss:1.4472  accuracy:0.3587\n",
      "第33代训练完成,历时572.1732339859009秒\n",
      "epoch 33 mean training loss:1.1287\n",
      "epoch 33 mean training accuracy:0.4547\n",
      "epoch 33 mean val loss:1.3814\n",
      "epoch 33 mean val accuracy:0.3707 \n",
      " \n",
      "train_batch:   0  loss:1.1817  accuracy:0.3915\n",
      "train_batch:  50  loss:1.2103  accuracy:0.4060\n",
      "train_batch: 100  loss:0.9876  accuracy:0.4746\n",
      "train_batch: 150  loss:1.1580  accuracy:0.4871\n",
      "val_batch:     0  loss:1.3473  accuracy:0.4097\n",
      "第34代训练完成,历时589.4878313541412秒\n",
      "epoch 34 mean training loss:1.1240\n",
      "epoch 34 mean training accuracy:0.4563\n",
      "epoch 34 mean val loss:1.3841\n",
      "epoch 34 mean val accuracy:0.3750 \n",
      " \n",
      "train_batch:   0  loss:1.2032  accuracy:0.3866\n",
      "train_batch:  50  loss:1.2591  accuracy:0.4241\n",
      "train_batch: 100  loss:1.1234  accuracy:0.4949\n",
      "train_batch: 150  loss:1.0273  accuracy:0.4957\n",
      "val_batch:     0  loss:1.3013  accuracy:0.3646\n",
      "第35代训练完成,历时606.792916059494秒\n",
      "epoch 35 mean training loss:1.1207\n",
      "epoch 35 mean training accuracy:0.4595\n",
      "epoch 35 mean val loss:1.3831\n",
      "epoch 35 mean val accuracy:0.3688 \n",
      " \n",
      "train_batch:   0  loss:0.9765  accuracy:0.4699\n",
      "train_batch:  50  loss:1.4650  accuracy:0.3547\n",
      "train_batch: 100  loss:1.0902  accuracy:0.4456\n",
      "train_batch: 150  loss:0.9847  accuracy:0.5000\n",
      "val_batch:     0  loss:1.4565  accuracy:0.3617\n",
      "第36代训练完成,历时624.1158671379089秒\n",
      "epoch 36 mean training loss:1.1164\n",
      "epoch 36 mean training accuracy:0.4617\n",
      "epoch 36 mean val loss:1.3862\n",
      "epoch 36 mean val accuracy:0.3792 \n",
      " \n",
      "train_batch:   0  loss:1.2538  accuracy:0.4600\n",
      "train_batch:  50  loss:0.9488  accuracy:0.5561\n",
      "train_batch: 100  loss:1.0500  accuracy:0.4962\n",
      "train_batch: 150  loss:1.2594  accuracy:0.4296\n",
      "val_batch:     0  loss:1.4205  accuracy:0.3826\n",
      "第37代训练完成,历时641.4306123256683秒\n",
      "epoch 37 mean training loss:1.1129\n",
      "epoch 37 mean training accuracy:0.4621\n",
      "epoch 37 mean val loss:1.3812\n",
      "epoch 37 mean val accuracy:0.3766 \n",
      " \n",
      "train_batch:   0  loss:1.2732  accuracy:0.4033\n",
      "train_batch:  50  loss:0.9884  accuracy:0.5283\n",
      "train_batch: 100  loss:1.1119  accuracy:0.4965\n",
      "train_batch: 150  loss:1.2697  accuracy:0.4264\n",
      "val_batch:     0  loss:1.5052  accuracy:0.3594\n",
      "第38代训练完成,历时658.7561392784119秒\n",
      "epoch 38 mean training loss:1.1085\n",
      "epoch 38 mean training accuracy:0.4653\n",
      "epoch 38 mean val loss:1.3900\n",
      "epoch 38 mean val accuracy:0.3715 \n",
      " \n",
      "train_batch:   0  loss:1.1453  accuracy:0.4497\n",
      "train_batch:  50  loss:0.8778  accuracy:0.5730\n",
      "train_batch: 100  loss:1.0863  accuracy:0.5058\n",
      "train_batch: 150  loss:1.3777  accuracy:0.3662\n",
      "val_batch:     0  loss:1.4233  accuracy:0.3809\n",
      "第39代训练完成,历时676.0963039398193秒\n",
      "epoch 39 mean training loss:1.1066\n",
      "epoch 39 mean training accuracy:0.4650\n",
      "epoch 39 mean val loss:1.3770\n",
      "epoch 39 mean val accuracy:0.3751 \n",
      " \n",
      "train_batch:   0  loss:1.0416  accuracy:0.4892\n",
      "train_batch:  50  loss:0.9956  accuracy:0.4860\n",
      "train_batch: 100  loss:1.2080  accuracy:0.4103\n",
      "train_batch: 150  loss:1.1850  accuracy:0.4401\n",
      "val_batch:     0  loss:1.5156  accuracy:0.3366\n",
      "第40代训练完成,历时693.4331150054932秒\n",
      "epoch 40 mean training loss:1.1029\n",
      "epoch 40 mean training accuracy:0.4673\n",
      "epoch 40 mean val loss:1.3636\n",
      "epoch 40 mean val accuracy:0.3802 \n",
      " \n",
      "train_batch:   0  loss:1.3156  accuracy:0.3778\n",
      "train_batch:  50  loss:1.0839  accuracy:0.4510\n",
      "train_batch: 100  loss:1.0177  accuracy:0.5294\n",
      "train_batch: 150  loss:1.1672  accuracy:0.4887\n",
      "val_batch:     0  loss:1.1102  accuracy:0.4321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第41代训练完成,历时710.753725528717秒\n",
      "epoch 41 mean training loss:1.1005\n",
      "epoch 41 mean training accuracy:0.4683\n",
      "epoch 41 mean val loss:1.3711\n",
      "epoch 41 mean val accuracy:0.3761 \n",
      " \n",
      "train_batch:   0  loss:0.9857  accuracy:0.4854\n",
      "train_batch:  50  loss:1.0387  accuracy:0.4860\n",
      "train_batch: 100  loss:0.9914  accuracy:0.4983\n",
      "train_batch: 150  loss:1.0535  accuracy:0.4375\n",
      "val_batch:     0  loss:1.4588  accuracy:0.3651\n",
      "第42代训练完成,历时728.0653424263秒\n",
      "epoch 42 mean training loss:1.0985\n",
      "epoch 42 mean training accuracy:0.4696\n",
      "epoch 42 mean val loss:1.3841\n",
      "epoch 42 mean val accuracy:0.3764 \n",
      " \n",
      "train_batch:   0  loss:1.3116  accuracy:0.4347\n",
      "train_batch:  50  loss:1.1381  accuracy:0.4703\n",
      "train_batch: 100  loss:1.1224  accuracy:0.4175\n",
      "train_batch: 150  loss:1.1214  accuracy:0.4575\n",
      "val_batch:     0  loss:1.4697  accuracy:0.3285\n",
      "第43代训练完成,历时745.3863489627838秒\n",
      "epoch 43 mean training loss:1.0955\n",
      "epoch 43 mean training accuracy:0.4704\n",
      "epoch 43 mean val loss:1.3752\n",
      "epoch 43 mean val accuracy:0.3779 \n",
      " \n",
      "train_batch:   0  loss:0.9792  accuracy:0.4861\n",
      "train_batch:  50  loss:1.0119  accuracy:0.5086\n",
      "train_batch: 100  loss:1.0129  accuracy:0.4350\n",
      "train_batch: 150  loss:1.0653  accuracy:0.4809\n",
      "val_batch:     0  loss:1.2774  accuracy:0.3939\n",
      "第44代训练完成,历时762.8212435245514秒\n",
      "epoch 44 mean training loss:1.0944\n",
      "epoch 44 mean training accuracy:0.4704\n",
      "epoch 44 mean val loss:1.3902\n",
      "epoch 44 mean val accuracy:0.3727 \n",
      " \n",
      "train_batch:   0  loss:1.1326  accuracy:0.4846\n",
      "train_batch:  50  loss:1.2407  accuracy:0.4665\n",
      "train_batch: 100  loss:1.0795  accuracy:0.5231\n",
      "train_batch: 150  loss:1.0874  accuracy:0.4311\n",
      "val_batch:     0  loss:1.3839  accuracy:0.3412\n",
      "第45代训练完成,历时780.1344523429871秒\n",
      "epoch 45 mean training loss:1.0928\n",
      "epoch 45 mean training accuracy:0.4727\n",
      "epoch 45 mean val loss:1.3834\n",
      "epoch 45 mean val accuracy:0.3737 \n",
      " \n",
      "train_batch:   0  loss:1.1681  accuracy:0.4685\n",
      "train_batch:  50  loss:0.9694  accuracy:0.4791\n",
      "train_batch: 100  loss:1.0560  accuracy:0.4837\n",
      "train_batch: 150  loss:1.0568  accuracy:0.4914\n",
      "val_batch:     0  loss:1.1776  accuracy:0.4384\n",
      "第46代训练完成,历时797.456782579422秒\n",
      "epoch 46 mean training loss:1.0908\n",
      "epoch 46 mean training accuracy:0.4722\n",
      "epoch 46 mean val loss:1.3810\n",
      "epoch 46 mean val accuracy:0.3800 \n",
      " \n",
      "train_batch:   0  loss:1.2791  accuracy:0.4628\n",
      "train_batch:  50  loss:1.0494  accuracy:0.4327\n",
      "train_batch: 100  loss:1.1638  accuracy:0.4677\n",
      "train_batch: 150  loss:1.0406  accuracy:0.4677\n",
      "val_batch:     0  loss:1.4493  accuracy:0.3582\n",
      "第47代训练完成,历时814.778858423233秒\n",
      "epoch 47 mean training loss:1.0884\n",
      "epoch 47 mean training accuracy:0.4725\n",
      "epoch 47 mean val loss:1.3788\n",
      "epoch 47 mean val accuracy:0.3781 \n",
      " \n",
      "train_batch:   0  loss:1.0172  accuracy:0.5589\n",
      "train_batch:  50  loss:1.1356  accuracy:0.4627\n",
      "train_batch: 100  loss:1.0491  accuracy:0.5016\n",
      "train_batch: 150  loss:0.9910  accuracy:0.5226\n",
      "val_batch:     0  loss:1.1776  accuracy:0.4212\n",
      "第48代训练完成,历时832.1233294010162秒\n",
      "epoch 48 mean training loss:1.0867\n",
      "epoch 48 mean training accuracy:0.4744\n",
      "epoch 48 mean val loss:1.3765\n",
      "epoch 48 mean val accuracy:0.3751 \n",
      " \n",
      "train_batch:   0  loss:1.0931  accuracy:0.4697\n",
      "train_batch:  50  loss:1.1151  accuracy:0.4769\n",
      "train_batch: 100  loss:0.8956  accuracy:0.5486\n",
      "train_batch: 150  loss:1.1847  accuracy:0.4719\n",
      "val_batch:     0  loss:1.4793  accuracy:0.3393\n",
      "第49代训练完成,历时849.4483697414398秒\n",
      "epoch 49 mean training loss:1.0883\n",
      "epoch 49 mean training accuracy:0.4731\n",
      "epoch 49 mean val loss:1.3910\n",
      "epoch 49 mean val accuracy:0.3795 \n",
      " \n",
      "train_batch:   0  loss:1.0540  accuracy:0.4150\n",
      "train_batch:  50  loss:1.1129  accuracy:0.4587\n",
      "train_batch: 100  loss:1.0802  accuracy:0.4728\n",
      "train_batch: 150  loss:1.0350  accuracy:0.4963\n",
      "val_batch:     0  loss:1.5926  accuracy:0.3152\n",
      "第50代训练完成,历时866.7793381214142秒\n",
      "epoch 50 mean training loss:1.0865\n",
      "epoch 50 mean training accuracy:0.4751\n",
      "epoch 50 mean val loss:1.3760\n",
      "epoch 50 mean val accuracy:0.3771 \n",
      " \n",
      "训练结束,训练时长： 866.7795813083649 秒\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70dc4ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14114237015478706\n"
     ]
    }
   ],
   "source": [
    "# 计算Bleu分数\n",
    "\n",
    "from torchmetrics import BLEUScore\n",
    "from statistics import mean\n",
    "\n",
    "def turn_numlist_into_strlist(num_list):\n",
    "    return [' '.join(list(map(str,num_list)))]\n",
    "\"\"\"将数字列表转化为bleu计算的字符串列表\"\"\"\n",
    "\n",
    "bleu = BLEUScore(5)\n",
    "\n",
    "bleu_list = []\n",
    "for batch_idx, batch_data in enumerate(val_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(**batch_data)\n",
    "            loss = out['loss']\n",
    "            labels = batch_data['labels'][:, 1:].tolist()\n",
    "            outputs = out['logits'].argmax(dim=2)[:, :-1].tolist()\n",
    "#             print(labels)\n",
    "            fix_outputs = []\n",
    "            fix_labels = []\n",
    "            fix_idx = []\n",
    "\n",
    "            for seq_num in labels:\n",
    "                fix_labels.append(seq_num[:len(seq_num)-seq_num.count(23)])\n",
    "                fix_idx.append(len(seq_num)-seq_num.count(23))\n",
    "            for idx, seq_num in enumerate(outputs):\n",
    "                fix_outputs.append(seq_num[:fix_idx[idx]])\n",
    "           \n",
    "            str_labels = []\n",
    "            str_outputs = []\n",
    "            \n",
    "            for o in fix_outputs:\n",
    "                str_outputs.append(turn_numlist_into_strlist(o))\n",
    "            \n",
    "            for l in fix_labels:\n",
    "                str_labels.append(turn_numlist_into_strlist(l))\n",
    "#             print(str_labels)\n",
    "            \n",
    "            for i, c in enumerate(str_outputs):\n",
    "#                 print(i ,c)\n",
    "                bleu_list.append(bleu(c, [str_labels[i]]).tolist())\n",
    "        \n",
    "# print(bleu_list)\n",
    "print(mean(bleu_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf53f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12443.9808\n"
     ]
    }
   ],
   "source": [
    "print(sum(i.numel() for i in model.parameters()) / 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aead84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "if mode == 'pretrain':\n",
    "    model.save_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64raw-20epochs/')  # when pretrain model\n",
    "elif mode == 'finetune':\n",
    "    torch.save(model, './save_model/finetune-model/finetune_with_AMPbert_data/finetune-10-48-GPT-'+str(epochs)+'epochs')  # finetune model\n",
    "else:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2644c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 结果作图\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [(x+1) for x in range(len(train_loss_list))]\n",
    "x2 = [(x+1) for x in range(len(val_acc_list))]\n",
    "y1 = train_loss_list\n",
    "y2 = train_acc_list\n",
    "y3 = val_loss_list\n",
    "y4 = val_acc_list\n",
    "\n",
    "plt.plot(x1, y1, label=\"AMP training loss\")\n",
    "plt.plot(x1, y3, label=\"AMP val_loss\")\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('AMP train losses show')\n",
    "plt.legend()\n",
    "if mode == 'pretrain':\n",
    "    plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/pretrain_result/'+\n",
    "                mode+'10-48washed-'+str(epochs)+'epochs_loss.jpg')\n",
    "elif mode == 'finetune':\n",
    "    plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/finetune_result/'+\n",
    "                mode+'10-48washed-'+str(epochs)+'epochs_loss.jpg')\n",
    "else:\n",
    "    pass\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(x2, y2, label=\"AMP train_acc curse\")\n",
    "plt.plot(x2, y4, label=\"AMP val_acc curse\")\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('acc')\n",
    "plt.title('AMP val_acc show')\n",
    "plt.legend()\n",
    "if mode == 'pretrain':\n",
    "    plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/pretrain_result/'+\n",
    "                mode+'10-48washed-'+str(epochs)+'epochs_accuracy.jpg')\n",
    "elif mode == 'finetune':\n",
    "    plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/finetune_result/'+\n",
    "                mode+'10-48washed-'+str(epochs)+'epochs_accuracy.jpg')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

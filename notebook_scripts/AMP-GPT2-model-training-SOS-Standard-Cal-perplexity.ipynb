{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656682a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3276f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose train mode\n",
    "global mode\n",
    "# mode = 'pretrain'\n",
    "mode = 'finetune'\n",
    "# mode = 'else'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6066b4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizer(name_or_path='', vocab_size=23, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]'})\n"
     ]
    }
   ],
   "source": [
    "# device and tokenizer\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer('./vocab_file/vocab.json', './vocab_file/merges.txt')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "if mode == 'pretrain':\n",
    "    tokenizer.save_pretrained('./save_model/pretrain_model/pretrained-gpt-10-64raw-50epochs') # when pretrain model\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9eff80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        if mode == 'finetune':\n",
    "#             with open('./data/ADP3_amp.txt') as f:  # when finetune\n",
    "            with open('./data/ADP3_amp.txt') as f:  # when finetune\n",
    "                lines = f.readlines()\n",
    "        elif mode == 'pretrain':\n",
    "            with open('./data/pretrain_data/uniprot10-63.txt') as f:  # when pretrain model \n",
    "                lines = f.readlines()\n",
    "        else:\n",
    "            print('train mode error')\n",
    "            with open('./data/ADP3_amp.txt') as f:\n",
    "                lines = f.readlines()\n",
    "        lines = [i.strip() for i in lines]\n",
    "\n",
    "        self.lines = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.lines[i]\n",
    "\n",
    "\n",
    "global val_split\n",
    "if mode == 'pretrain':\n",
    "    val_split = 0.01\n",
    "elif mode =='finetune':\n",
    "    val_split = 0.1\n",
    "else:\n",
    "    val_split = 0.4\n",
    "\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(val_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = Data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = Data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "def collate_fn(data):\n",
    "    data = tokenizer.batch_encode_plus(data,\n",
    "                                       padding=True,\n",
    "                                       truncation=True,\n",
    "                                       max_length=64,\n",
    "                                       return_tensors='pt')\n",
    "\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64, \n",
    "    sampler=train_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,)\n",
    "\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64, \n",
    "    sampler=val_sampler,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,)\n",
    "\n",
    "# for i, data in enumerate(val_loader):\n",
    "    \n",
    "\n",
    "#     for k, v in data.items():\n",
    "#         print(k, v.shape, v)\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de835ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GPT model\n",
    "\n",
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "# Initializing a GPT2 configuration\n",
    "configuration = GPT2Config(n_layer=12, \n",
    "                           n_head=12,\n",
    "                           n_embd=768)\n",
    "\n",
    "# print(configuration)\n",
    "\n",
    "# Initializing a model from the configuration\n",
    "if mode == 'pretrain':\n",
    "    model = GPT2LMHeadModel(configuration)  # when pretrain model\n",
    "elif mode == 'finetune':\n",
    "    model = GPT2LMHeadModel.from_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64washed-30epochs')\n",
    "else:\n",
    "    pass\n",
    "#     model = GPT2LMHeadModel.from_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64raw-20epochs/')\n",
    "# model = torch.load('./save_model/pretrained-gpt-10-48-30epochs/pytorch_model.bin')  # pretrain model use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f560aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers.optimization import get_scheduler\n",
    "from torchmetrics import Perplexity\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\",num_classes=23,ignore_index=23)\n",
    "accuracy = accuracy.to(device)\n",
    "\n",
    "perplexity = Perplexity(ignore_index=23).to(device)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_acc_list =[]\n",
    "val_acc_list = []\n",
    "train_pp_list = []\n",
    "val_pp_list = []\n",
    "    \n",
    "#训练\n",
    "def train():\n",
    "    global model\n",
    "#     device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-6)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=400,\n",
    "                              num_training_steps=len(train_loader)*epochs,\n",
    "                              optimizer=optimizer)\n",
    "\n",
    "    model.train()\n",
    "    print('开始训练')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "        train_pp = []\n",
    "        val_loss = []\n",
    "        val_accuracy = []\n",
    "        val_pp = []\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(**batch_data)\n",
    "#             print(out.keys())\n",
    "            loss = out['loss']\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            \n",
    "            labels = batch_data['labels'][:, 1:]\n",
    "            outs = out['logits'].argmax(dim=2)[:, :-1]\n",
    "#             print(out)\n",
    "#             print(labels)\n",
    "            \n",
    "            perplexity_train = perplexity(out['logits'][:,:-1,:], labels)\n",
    "            train_acc = accuracy(outs, labels)\n",
    "            \n",
    "            train_accuracy.append(train_acc.tolist())\n",
    "            train_pp.append(perplexity_train.tolist())\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('train_batch: {:3d}  loss:{:.4f}  accuracy:{:.4f}  perplexity:{:.4f}'\n",
    "                      .format(batch_idx, loss.item(), train_acc.item(), perplexity_train.item()))\n",
    "            \n",
    "        for batch_idx, batch_data in enumerate(val_loader):\n",
    "            batch_data = batch_data.to(device)\n",
    "            out = model(**batch_data)\n",
    "            loss = out['loss']\n",
    "            labels = batch_data['labels'][:, 1:]\n",
    "            outs = out['logits'].argmax(dim=2)[:, :-1]\n",
    "            val_acc = accuracy(outs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            val_accuracy.append(val_acc.tolist())\n",
    "            \n",
    "            perplexity_test = perplexity(out['logits'][:,:-1,:], labels)\n",
    "            val_pp.append(perplexity_test.tolist())\n",
    "#             total_perplexity_test += perplexity_test * 64 # len(inputs)\n",
    "#         perplexity_test = total_perplexity_test / len(batch_data)\n",
    "#         print('Epoch: %d, Test Perplexity: %.4f' % (epoch+1, perplexity_test))\n",
    "        \n",
    "            if batch_idx % 50 == 0:\n",
    "                print('val_batch:   {:3d}  loss:{:.4f}  accuracy:{:.4f}  perplexity:{:.4f}'\n",
    "                      .format(batch_idx, loss.item(), val_acc.item(), perplexity_test.item()))\n",
    "            \n",
    "        train_loss_list.append(np.mean(train_loss))\n",
    "        train_acc_list.append(np.mean(train_accuracy))\n",
    "        train_pp_list.append(np.mean(train_pp))\n",
    "        val_loss_list.append(np.mean(val_loss))\n",
    "        val_acc_list.append(np.mean(val_accuracy))\n",
    "        val_pp_list.append(np.mean(val_pp))\n",
    "        train_time = time.time()\n",
    "        print('第{}代训练完成,历时{}秒'.format(epoch+1,train_time-start_time))\n",
    "        print('epoch {} mean training loss:{:.4f}'.format(epoch+1, np.mean(train_loss)))\n",
    "        print('epoch {} mean training accuracy:{:.4f}'.format(epoch+1, np.mean(train_accuracy)))\n",
    "        print('epoch {} mean training perplexity:{:.4f}'.format(epoch+1, np.mean(train_pp)))\n",
    "        print('epoch {} mean val loss:{:.4f}'.format(epoch+1, np.mean(val_loss)))\n",
    "        print('epoch {} mean val accuracy:{:.4f} '.format(epoch+1, np.mean(val_accuracy)))\n",
    "        print('epoch {} mean val perplexity:{:.4f} '.format(epoch+1, np.mean(val_pp)))\n",
    "        print(' ')\n",
    "        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('训练结束,训练时长：',end_time-start_time, '秒')   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e73cb1f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练\n",
      "train_batch:   0  loss:1.4211  accuracy:0.1414  perplexity:16.4079\n",
      "train_batch:  50  loss:1.3451  accuracy:0.1506  perplexity:16.0595\n",
      "val_batch:     0  loss:1.5209  accuracy:0.1799  perplexity:14.9772\n",
      "第1代训练完成,历时23.507112979888916秒\n",
      "epoch 1 mean training loss:1.4416\n",
      "epoch 1 mean training accuracy:0.1502\n",
      "epoch 1 mean training perplexity:16.1885\n",
      "epoch 1 mean val loss:1.4703\n",
      "epoch 1 mean val accuracy:0.1629 \n",
      "epoch 1 mean val perplexity:15.5706 \n",
      " \n",
      "train_batch:   0  loss:1.3644  accuracy:0.1555  perplexity:15.4248\n",
      "train_batch:  50  loss:1.3489  accuracy:0.1950  perplexity:13.9398\n",
      "val_batch:     0  loss:1.3611  accuracy:0.1779  perplexity:14.4641\n",
      "第2代训练完成,历时46.66934895515442秒\n",
      "epoch 2 mean training loss:1.3717\n",
      "epoch 2 mean training accuracy:0.1689\n",
      "epoch 2 mean training perplexity:14.9685\n",
      "epoch 2 mean val loss:1.4001\n",
      "epoch 2 mean val accuracy:0.1867 \n",
      "epoch 2 mean val perplexity:14.1032 \n",
      " \n",
      "train_batch:   0  loss:1.4946  accuracy:0.1905  perplexity:13.8138\n",
      "train_batch:  50  loss:1.2920  accuracy:0.2037  perplexity:13.0644\n",
      "val_batch:     0  loss:1.5264  accuracy:0.1733  perplexity:14.5045\n",
      "第3代训练完成,历时69.944326877594秒\n",
      "epoch 3 mean training loss:1.3148\n",
      "epoch 3 mean training accuracy:0.1939\n",
      "epoch 3 mean training perplexity:13.5318\n",
      "epoch 3 mean val loss:1.3481\n",
      "epoch 3 mean val accuracy:0.2102 \n",
      "epoch 3 mean val perplexity:12.9901 \n",
      " \n",
      "train_batch:   0  loss:1.3218  accuracy:0.1854  perplexity:13.7738\n",
      "train_batch:  50  loss:1.3345  accuracy:0.2014  perplexity:12.5712\n",
      "第4代训练完成,历时93.35977578163147秒\n",
      "epoch 4 mean training loss:1.2707\n",
      "epoch 4 mean training accuracy:0.2167\n",
      "epoch 4 mean training perplexity:12.5577\n",
      "epoch 4 mean val loss:1.3164\n",
      "epoch 4 mean val accuracy:0.2314 \n",
      "epoch 4 mean val perplexity:12.3225 \n",
      " \n",
      "train_batch:   0  loss:1.2474  accuracy:0.2359  perplexity:12.0310\n",
      "train_batch:  50  loss:1.1307  accuracy:0.2302  perplexity:11.5991\n",
      "val_batch:     0  loss:1.3531  accuracy:0.2525  perplexity:12.0352\n",
      "第5代训练完成,历时116.81848502159119秒\n",
      "epoch 5 mean training loss:1.2336\n",
      "epoch 5 mean training accuracy:0.2418\n",
      "epoch 5 mean training perplexity:11.7386\n",
      "epoch 5 mean val loss:1.2968\n",
      "epoch 5 mean val accuracy:0.2463 \n",
      "epoch 5 mean val perplexity:11.7016 \n",
      " \n",
      "train_batch:   0  loss:1.3022  accuracy:0.2069  perplexity:12.9560\n",
      "train_batch:  50  loss:1.2451  accuracy:0.2650  perplexity:10.7837\n",
      "val_batch:     0  loss:1.3919  accuracy:0.2336  perplexity:11.8090\n",
      "第6代训练完成,历时140.34787893295288秒\n",
      "epoch 6 mean training loss:1.2006\n",
      "epoch 6 mean training accuracy:0.2622\n",
      "epoch 6 mean training perplexity:11.0673\n",
      "epoch 6 mean val loss:1.2883\n",
      "epoch 6 mean val accuracy:0.2542 \n",
      "epoch 6 mean val perplexity:11.4647 \n",
      " \n",
      "train_batch:   0  loss:1.1970  accuracy:0.2941  perplexity:10.0641\n",
      "train_batch:  50  loss:0.9758  accuracy:0.3135  perplexity:9.0039\n",
      "val_batch:     0  loss:1.2704  accuracy:0.2599  perplexity:10.7623\n",
      "第7代训练完成,历时163.89006567001343秒\n",
      "epoch 7 mean training loss:1.1771\n",
      "epoch 7 mean training accuracy:0.2769\n",
      "epoch 7 mean training perplexity:10.5776\n",
      "epoch 7 mean val loss:1.2547\n",
      "epoch 7 mean val accuracy:0.2690 \n",
      "epoch 7 mean val perplexity:10.9225 \n",
      " \n",
      "train_batch:   0  loss:1.2065  accuracy:0.2637  perplexity:10.5210\n",
      "train_batch:  50  loss:1.2117  accuracy:0.2730  perplexity:10.4288\n",
      "val_batch:     0  loss:1.2889  accuracy:0.2779  perplexity:10.8236\n",
      "第8代训练完成,历时187.44786739349365秒\n",
      "epoch 8 mean training loss:1.1586\n",
      "epoch 8 mean training accuracy:0.2885\n",
      "epoch 8 mean training perplexity:10.2036\n",
      "epoch 8 mean val loss:1.2581\n",
      "epoch 8 mean val accuracy:0.2707 \n",
      "epoch 8 mean val perplexity:10.8521 \n",
      " \n",
      "train_batch:   0  loss:1.0838  accuracy:0.3193  perplexity:8.9741\n",
      "train_batch:  50  loss:1.2061  accuracy:0.2591  perplexity:10.6871\n",
      "val_batch:     0  loss:1.2303  accuracy:0.2941  perplexity:10.1272\n",
      "第9代训练完成,历时211.05759620666504秒\n",
      "epoch 9 mean training loss:1.1443\n",
      "epoch 9 mean training accuracy:0.2983\n",
      "epoch 9 mean training perplexity:9.8780\n",
      "epoch 9 mean val loss:1.2172\n",
      "epoch 9 mean val accuracy:0.2878 \n",
      "epoch 9 mean val perplexity:10.2646 \n",
      " \n",
      "train_batch:  50  loss:1.1864  accuracy:0.3319  perplexity:8.7166\n",
      "val_batch:     0  loss:1.1374  accuracy:0.2826  perplexity:10.3690\n",
      "第10代训练完成,历时234.6126470565796秒\n",
      "epoch 10 mean training loss:1.1269\n",
      "epoch 10 mean training accuracy:0.3070\n",
      "epoch 10 mean training perplexity:9.5956\n",
      "epoch 10 mean val loss:1.2130\n",
      "epoch 10 mean val accuracy:0.2897 \n",
      "epoch 10 mean val perplexity:10.2266 \n",
      " \n",
      "train_batch:   0  loss:1.2425  accuracy:0.3014  perplexity:10.1327\n",
      "train_batch:  50  loss:0.9927  accuracy:0.3461  perplexity:8.3928\n",
      "val_batch:     0  loss:1.2439  accuracy:0.2799  perplexity:10.4505\n",
      "第11代训练完成,历时258.1166830062866秒\n",
      "epoch 11 mean training loss:1.1161\n",
      "epoch 11 mean training accuracy:0.3170\n",
      "epoch 11 mean training perplexity:9.3407\n",
      "epoch 11 mean val loss:1.2137\n",
      "epoch 11 mean val accuracy:0.2903 \n",
      "epoch 11 mean val perplexity:10.1253 \n",
      " \n",
      "train_batch:   0  loss:1.2206  accuracy:0.2872  perplexity:10.1394\n",
      "train_batch:  50  loss:1.1839  accuracy:0.3441  perplexity:8.7000\n",
      "val_batch:     0  loss:1.0152  accuracy:0.3445  perplexity:8.6069\n",
      "第12代训练完成,历时281.6497640609741秒\n",
      "epoch 12 mean training loss:1.1026\n",
      "epoch 12 mean training accuracy:0.3246\n",
      "epoch 12 mean training perplexity:9.1279\n",
      "epoch 12 mean val loss:1.2130\n",
      "epoch 12 mean val accuracy:0.2921 \n",
      "epoch 12 mean val perplexity:10.1203 \n",
      " \n",
      "train_batch:   0  loss:0.9394  accuracy:0.3791  perplexity:7.7823\n",
      "train_batch:  50  loss:1.2165  accuracy:0.2905  perplexity:10.4065\n",
      "val_batch:     0  loss:1.2495  accuracy:0.2936  perplexity:10.1967\n",
      "第13代训练完成,历时305.2022051811218秒\n",
      "epoch 13 mean training loss:1.0896\n",
      "epoch 13 mean training accuracy:0.3316\n",
      "epoch 13 mean training perplexity:8.9069\n",
      "epoch 13 mean val loss:1.2132\n",
      "epoch 13 mean val accuracy:0.3044 \n",
      "epoch 13 mean val perplexity:9.8119 \n",
      " \n",
      "train_batch:   0  loss:1.0732  accuracy:0.3503  perplexity:8.2396\n",
      "train_batch:  50  loss:0.9834  accuracy:0.3678  perplexity:7.8013\n",
      "val_batch:     0  loss:1.2373  accuracy:0.2940  perplexity:10.1803\n",
      "第14代训练完成,历时328.70098996162415秒\n",
      "epoch 14 mean training loss:1.0804\n",
      "epoch 14 mean training accuracy:0.3389\n",
      "epoch 14 mean training perplexity:8.7013\n",
      "epoch 14 mean val loss:1.1815\n",
      "epoch 14 mean val accuracy:0.3074 \n",
      "epoch 14 mean val perplexity:9.6583 \n",
      " \n",
      "train_batch:   0  loss:1.0078  accuracy:0.3828  perplexity:7.6250\n",
      "train_batch:  50  loss:1.0749  accuracy:0.3183  perplexity:9.1844\n",
      "val_batch:     0  loss:1.1580  accuracy:0.2979  perplexity:10.0447\n",
      "第15代训练完成,历时352.24810886383057秒\n",
      "epoch 15 mean training loss:1.0678\n",
      "epoch 15 mean training accuracy:0.3459\n",
      "epoch 15 mean training perplexity:8.5340\n",
      "epoch 15 mean val loss:1.1788\n",
      "epoch 15 mean val accuracy:0.3124 \n",
      "epoch 15 mean val perplexity:9.5238 \n",
      " \n",
      "train_batch:   0  loss:0.9637  accuracy:0.3802  perplexity:7.6975\n",
      "train_batch:  50  loss:1.0709  accuracy:0.3313  perplexity:8.8171\n",
      "val_batch:     0  loss:1.1818  accuracy:0.3145  perplexity:9.2452\n",
      "第16代训练完成,历时375.78631234169006秒\n",
      "epoch 16 mean training loss:1.0575\n",
      "epoch 16 mean training accuracy:0.3516\n",
      "epoch 16 mean training perplexity:8.3846\n",
      "epoch 16 mean val loss:1.1755\n",
      "epoch 16 mean val accuracy:0.3180 \n",
      "epoch 16 mean val perplexity:9.4990 \n",
      " \n",
      "train_batch:   0  loss:1.0783  accuracy:0.3394  perplexity:9.0066\n",
      "train_batch:  50  loss:0.9834  accuracy:0.3686  perplexity:7.9239\n",
      "val_batch:     0  loss:1.0777  accuracy:0.3464  perplexity:8.5328\n",
      "第17代训练完成,历时399.3161895275116秒\n",
      "epoch 17 mean training loss:1.0482\n",
      "epoch 17 mean training accuracy:0.3583\n",
      "epoch 17 mean training perplexity:8.2260\n",
      "epoch 17 mean val loss:1.1641\n",
      "epoch 17 mean val accuracy:0.3201 \n",
      "epoch 17 mean val perplexity:9.3560 \n",
      " \n",
      "train_batch:   0  loss:1.1166  accuracy:0.3263  perplexity:9.1087\n",
      "train_batch:  50  loss:1.0271  accuracy:0.3612  perplexity:8.3315\n",
      "val_batch:     0  loss:1.2127  accuracy:0.3251  perplexity:9.4902\n",
      "第18代训练完成,历时422.85601234436035秒\n",
      "epoch 18 mean training loss:1.0393\n",
      "epoch 18 mean training accuracy:0.3632\n",
      "epoch 18 mean training perplexity:8.0788\n",
      "epoch 18 mean val loss:1.1724\n",
      "epoch 18 mean val accuracy:0.3243 \n",
      "epoch 18 mean val perplexity:9.3310 \n",
      " \n",
      "train_batch:   0  loss:1.0453  accuracy:0.3201  perplexity:9.2663\n",
      "train_batch:  50  loss:0.9880  accuracy:0.3743  perplexity:7.5461\n",
      "val_batch:     0  loss:1.2004  accuracy:0.3383  perplexity:9.2004\n",
      "第19代训练完成,历时446.39015913009644秒\n",
      "epoch 19 mean training loss:1.0303\n",
      "epoch 19 mean training accuracy:0.3690\n",
      "epoch 19 mean training perplexity:7.9565\n",
      "epoch 19 mean val loss:1.1590\n",
      "epoch 19 mean val accuracy:0.3305 \n",
      "epoch 19 mean val perplexity:9.1432 \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch:   0  loss:1.0542  accuracy:0.3235  perplexity:9.1769\n",
      "train_batch:  50  loss:1.0117  accuracy:0.3649  perplexity:8.1135\n",
      "val_batch:     0  loss:1.1677  accuracy:0.2898  perplexity:10.1705\n",
      "第20代训练完成,历时469.920743227005秒\n",
      "epoch 20 mean training loss:1.0221\n",
      "epoch 20 mean training accuracy:0.3755\n",
      "epoch 20 mean training perplexity:7.8159\n",
      "epoch 20 mean val loss:1.1571\n",
      "epoch 20 mean val accuracy:0.3278 \n",
      "epoch 20 mean val perplexity:9.2370 \n",
      " \n",
      "train_batch:   0  loss:0.9048  accuracy:0.4454  perplexity:6.3453\n",
      "train_batch:  50  loss:1.0944  accuracy:0.3843  perplexity:7.5128\n",
      "val_batch:     0  loss:1.1457  accuracy:0.3366  perplexity:8.9830\n",
      "第21代训练完成,历时493.42784786224365秒\n",
      "epoch 21 mean training loss:1.0158\n",
      "epoch 21 mean training accuracy:0.3797\n",
      "epoch 21 mean training perplexity:7.6974\n",
      "epoch 21 mean val loss:1.1563\n",
      "epoch 21 mean val accuracy:0.3314 \n",
      "epoch 21 mean val perplexity:9.0814 \n",
      " \n",
      "train_batch:   0  loss:1.0837  accuracy:0.3245  perplexity:8.9451\n",
      "train_batch:  50  loss:1.1997  accuracy:0.3248  perplexity:9.0658\n",
      "val_batch:     0  loss:1.0508  accuracy:0.3845  perplexity:7.6734\n",
      "第22代训练完成,历时516.9572200775146秒\n",
      "epoch 22 mean training loss:1.0066\n",
      "epoch 22 mean training accuracy:0.3845\n",
      "epoch 22 mean training perplexity:7.5821\n",
      "epoch 22 mean val loss:1.1517\n",
      "epoch 22 mean val accuracy:0.3295 \n",
      "epoch 22 mean val perplexity:9.1345 \n",
      " \n",
      "train_batch:   0  loss:1.0055  accuracy:0.3657  perplexity:7.8602\n",
      "train_batch:  50  loss:1.0565  accuracy:0.4017  perplexity:7.2135\n",
      "val_batch:     0  loss:1.0163  accuracy:0.3792  perplexity:7.7756\n",
      "第23代训练完成,历时540.4879035949707秒\n",
      "epoch 23 mean training loss:1.0007\n",
      "epoch 23 mean training accuracy:0.3877\n",
      "epoch 23 mean training perplexity:7.4884\n",
      "epoch 23 mean val loss:1.1400\n",
      "epoch 23 mean val accuracy:0.3405 \n",
      "epoch 23 mean val perplexity:8.8124 \n",
      " \n",
      "train_batch:   0  loss:1.1767  accuracy:0.3229  perplexity:8.9985\n",
      "train_batch:  50  loss:0.9876  accuracy:0.3844  perplexity:7.6579\n",
      "val_batch:     0  loss:1.4695  accuracy:0.2808  perplexity:11.3875\n",
      "第24代训练完成,历时564.0707058906555秒\n",
      "epoch 24 mean training loss:0.9924\n",
      "epoch 24 mean training accuracy:0.3921\n",
      "epoch 24 mean training perplexity:7.3717\n",
      "epoch 24 mean val loss:1.1367\n",
      "epoch 24 mean val accuracy:0.3423 \n",
      "epoch 24 mean val perplexity:8.8445 \n",
      " \n",
      "train_batch:   0  loss:0.9104  accuracy:0.4037  perplexity:7.1443\n",
      "train_batch:  50  loss:1.1382  accuracy:0.3172  perplexity:9.1222\n",
      "val_batch:     0  loss:1.2412  accuracy:0.3101  perplexity:9.7677\n",
      "第25代训练完成,历时587.5629303455353秒\n",
      "epoch 25 mean training loss:0.9881\n",
      "epoch 25 mean training accuracy:0.3965\n",
      "epoch 25 mean training perplexity:7.2812\n",
      "epoch 25 mean val loss:1.1446\n",
      "epoch 25 mean val accuracy:0.3420 \n",
      "epoch 25 mean val perplexity:8.8192 \n",
      " \n",
      "train_batch:   0  loss:1.0394  accuracy:0.3916  perplexity:7.4462\n",
      "train_batch:  50  loss:1.0724  accuracy:0.3634  perplexity:8.1451\n",
      "val_batch:     0  loss:1.2193  accuracy:0.3341  perplexity:8.6296\n",
      "第26代训练完成,历时611.0300543308258秒\n",
      "epoch 26 mean training loss:0.9827\n",
      "epoch 26 mean training accuracy:0.4008\n",
      "epoch 26 mean training perplexity:7.1808\n",
      "epoch 26 mean val loss:1.1415\n",
      "epoch 26 mean val accuracy:0.3420 \n",
      "epoch 26 mean val perplexity:8.9230 \n",
      " \n",
      "train_batch:   0  loss:1.0706  accuracy:0.3687  perplexity:7.7950\n",
      "train_batch:  50  loss:0.9295  accuracy:0.4083  perplexity:6.9996\n",
      "train_batch:  50  loss:0.8438  accuracy:0.5160  perplexity:4.9472\n",
      "val_batch:     0  loss:0.9847  accuracy:0.4154  perplexity:6.9653\n",
      "第36代训练完成,历时846.2594809532166秒\n",
      "epoch 36 mean training loss:0.9248\n",
      "epoch 36 mean training accuracy:0.4337\n",
      "epoch 36 mean training perplexity:6.4491\n",
      "epoch 36 mean val loss:1.1420\n",
      "epoch 36 mean val accuracy:0.3514 \n",
      "epoch 36 mean val perplexity:8.6742 \n",
      " \n",
      "train_batch:   0  loss:0.9959  accuracy:0.3942  perplexity:7.2527\n",
      "train_batch:  50  loss:0.8256  accuracy:0.4775  perplexity:5.4883\n",
      "val_batch:     0  loss:1.2232  accuracy:0.3365  perplexity:9.2087\n",
      "第37代训练完成,历时869.7910318374634秒\n",
      "epoch 37 mean training loss:0.9201\n",
      "epoch 37 mean training accuracy:0.4355\n",
      "epoch 37 mean training perplexity:6.3925\n",
      "epoch 37 mean val loss:1.1297\n",
      "epoch 37 mean val accuracy:0.3549 \n",
      "epoch 37 mean val perplexity:8.6539 \n",
      " \n",
      "train_batch:   0  loss:0.9986  accuracy:0.4068  perplexity:6.9835\n",
      "train_batch:  50  loss:0.8971  accuracy:0.4482  perplexity:6.0798\n",
      "val_batch:     0  loss:1.2102  accuracy:0.3488  perplexity:8.7984\n",
      "第38代训练完成,历时893.3969860076904秒\n",
      "epoch 38 mean training loss:0.9142\n",
      "epoch 38 mean training accuracy:0.4385\n",
      "epoch 38 mean training perplexity:6.3101\n",
      "epoch 38 mean val loss:1.1094\n",
      "epoch 38 mean val accuracy:0.3608 \n",
      "epoch 38 mean val perplexity:8.4266 \n",
      " \n",
      "train_batch:   0  loss:0.9178  accuracy:0.3853  perplexity:7.4107\n",
      "train_batch:  50  loss:0.8814  accuracy:0.4597  perplexity:5.8472\n",
      "val_batch:     0  loss:1.0416  accuracy:0.4011  perplexity:7.3146\n",
      "第39代训练完成,历时916.8910882472992秒\n",
      "epoch 39 mean training loss:0.9107\n",
      "epoch 39 mean training accuracy:0.4418\n",
      "epoch 39 mean training perplexity:6.2630\n",
      "epoch 39 mean val loss:1.1166\n",
      "epoch 39 mean val accuracy:0.3587 \n",
      "epoch 39 mean val perplexity:8.6164 \n",
      " \n",
      "train_batch:   0  loss:0.9645  accuracy:0.4293  perplexity:6.5016\n",
      "train_batch:  50  loss:0.6879  accuracy:0.4822  perplexity:5.2347\n",
      "val_batch:     0  loss:1.1803  accuracy:0.3975  perplexity:7.4497\n",
      "第40代训练完成,历时940.3704686164856秒\n",
      "epoch 40 mean training loss:0.9072\n",
      "epoch 40 mean training accuracy:0.4457\n",
      "epoch 40 mean training perplexity:6.2066\n",
      "epoch 40 mean val loss:1.1207\n",
      "epoch 40 mean val accuracy:0.3646 \n",
      "epoch 40 mean val perplexity:8.3766 \n",
      " \n",
      "train_batch:   0  loss:0.7566  accuracy:0.4616  perplexity:5.6634\n",
      "train_batch:  50  loss:0.8236  accuracy:0.4620  perplexity:5.8828\n",
      "val_batch:     0  loss:1.0670  accuracy:0.3719  perplexity:8.2241\n",
      "第41代训练完成,历时963.8761918544769秒\n",
      "epoch 41 mean training loss:0.9011\n",
      "epoch 41 mean training accuracy:0.4470\n",
      "epoch 41 mean training perplexity:6.1591\n",
      "epoch 41 mean val loss:1.1115\n",
      "epoch 41 mean val accuracy:0.3666 \n",
      "epoch 41 mean val perplexity:8.3951 \n",
      " \n",
      "train_batch:   0  loss:0.9191  accuracy:0.4573  perplexity:6.0026\n",
      "train_batch:  50  loss:1.0907  accuracy:0.3967  perplexity:7.3607\n",
      "val_batch:     0  loss:1.1527  accuracy:0.3559  perplexity:8.8295\n",
      "第42代训练完成,历时987.3790230751038秒\n",
      "epoch 42 mean training loss:0.8983\n",
      "epoch 42 mean training accuracy:0.4487\n",
      "epoch 42 mean training perplexity:6.1188\n",
      "epoch 42 mean val loss:1.1084\n",
      "epoch 42 mean val accuracy:0.3661 \n",
      "epoch 42 mean val perplexity:8.4955 \n",
      " \n",
      "train_batch:   0  loss:0.8185  accuracy:0.4791  perplexity:5.6571\n",
      "train_batch:  50  loss:0.7337  accuracy:0.5242  perplexity:4.8304\n",
      "val_batch:     0  loss:1.2602  accuracy:0.2869  perplexity:10.6624\n",
      "第43代训练完成,历时1010.8300080299377秒\n",
      "epoch 43 mean training loss:0.8953\n",
      "epoch 43 mean training accuracy:0.4529\n",
      "epoch 43 mean training perplexity:6.0581\n",
      "epoch 43 mean val loss:1.1145\n",
      "epoch 43 mean val accuracy:0.3622 \n",
      "epoch 43 mean val perplexity:8.5818 \n",
      " \n",
      "train_batch:   0  loss:0.7887  accuracy:0.5253  perplexity:4.8868\n",
      "train_batch:  50  loss:0.8848  accuracy:0.4383  perplexity:6.0612\n",
      "val_batch:     0  loss:1.0014  accuracy:0.3624  perplexity:8.1686\n",
      "第44代训练完成,历时1034.3160321712494秒\n",
      "epoch 44 mean training loss:0.8902\n",
      "epoch 44 mean training accuracy:0.4551\n",
      "epoch 44 mean training perplexity:6.0175\n",
      "epoch 44 mean val loss:1.1132\n",
      "epoch 44 mean val accuracy:0.3610 \n",
      "epoch 44 mean val perplexity:8.4669 \n",
      " \n",
      "train_batch:   0  loss:0.8556  accuracy:0.4563  perplexity:5.9846\n",
      "train_batch:  50  loss:0.9745  accuracy:0.3712  perplexity:7.6844\n",
      "val_batch:     0  loss:1.1624  accuracy:0.3662  perplexity:8.4890\n",
      "第45代训练完成,历时1057.8102717399597秒\n",
      "epoch 45 mean training loss:0.8856\n",
      "epoch 45 mean training accuracy:0.4575\n",
      "epoch 45 mean training perplexity:5.9787\n",
      "epoch 45 mean val loss:1.1217\n",
      "epoch 45 mean val accuracy:0.3624 \n",
      "epoch 45 mean val perplexity:8.5378 \n",
      " \n",
      "train_batch:   0  loss:1.1083  accuracy:0.4050  perplexity:7.0328\n",
      "train_batch:  50  loss:0.9033  accuracy:0.4713  perplexity:5.6934\n",
      "val_batch:     0  loss:1.2448  accuracy:0.3103  perplexity:10.0643\n",
      "第46代训练完成,历时1081.2770040035248秒\n",
      "epoch 46 mean training loss:0.8827\n",
      "epoch 46 mean training accuracy:0.4599\n",
      "epoch 46 mean training perplexity:5.9153\n",
      "epoch 46 mean val loss:1.1205\n",
      "epoch 46 mean val accuracy:0.3619 \n",
      "epoch 46 mean val perplexity:8.5243 \n",
      " \n",
      "train_batch:   0  loss:0.8311  accuracy:0.4838  perplexity:5.3996\n",
      "train_batch:  50  loss:0.8960  accuracy:0.4850  perplexity:5.5247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_batch:     0  loss:1.1369  accuracy:0.3528  perplexity:8.6844\n",
      "第47代训练完成,历时1104.7645363807678秒\n",
      "epoch 47 mean training loss:0.8785\n",
      "epoch 47 mean training accuracy:0.4617\n",
      "epoch 47 mean training perplexity:5.8810\n",
      "epoch 47 mean val loss:1.1160\n",
      "epoch 47 mean val accuracy:0.3703 \n",
      "epoch 47 mean val perplexity:8.4300 \n",
      " \n",
      "train_batch:   0  loss:0.9822  accuracy:0.4403  perplexity:6.1965\n",
      "train_batch:  50  loss:0.9438  accuracy:0.4361  perplexity:6.3305\n",
      "val_batch:     0  loss:1.0498  accuracy:0.3892  perplexity:7.8886\n",
      "第48代训练完成,历时1128.2565503120422秒\n",
      "epoch 48 mean training loss:0.8753\n",
      "epoch 48 mean training accuracy:0.4637\n",
      "epoch 48 mean training perplexity:5.8434\n",
      "epoch 48 mean val loss:1.1327\n",
      "epoch 48 mean val accuracy:0.3670 \n",
      "epoch 48 mean val perplexity:8.4554 \n",
      " \n",
      "train_batch:   0  loss:0.9128  accuracy:0.4578  perplexity:6.1568\n",
      "train_batch:  50  loss:0.7667  accuracy:0.5339  perplexity:4.7162\n",
      "val_batch:     0  loss:1.1130  accuracy:0.3508  perplexity:8.7464\n",
      "第49代训练完成,历时1151.7446439266205秒\n",
      "epoch 49 mean training loss:0.8698\n",
      "epoch 49 mean training accuracy:0.4653\n",
      "epoch 49 mean training perplexity:5.7913\n",
      "epoch 49 mean val loss:1.1118\n",
      "epoch 49 mean val accuracy:0.3676 \n",
      "epoch 49 mean val perplexity:8.4939 \n",
      " \n",
      "train_batch:   0  loss:0.7147  accuracy:0.5281  perplexity:4.6830\n",
      "train_batch:  50  loss:0.7518  accuracy:0.5005  perplexity:5.0538\n",
      "val_batch:     0  loss:1.0175  accuracy:0.4133  perplexity:7.3004\n",
      "第50代训练完成,历时1175.243161201477秒\n",
      "epoch 50 mean training loss:0.8677\n",
      "epoch 50 mean training accuracy:0.4682\n",
      "epoch 50 mean training perplexity:5.7576\n",
      "epoch 50 mean val loss:1.1134\n",
      "epoch 50 mean val accuracy:0.3731 \n",
      "epoch 50 mean val perplexity:8.4565 \n",
      " \n",
      "train_batch:   0  loss:0.8493  accuracy:0.5046  perplexity:5.0659\n",
      "train_batch:  50  loss:0.6610  accuracy:0.5433  perplexity:4.3175\n",
      "val_batch:     0  loss:1.2331  accuracy:0.2960  perplexity:10.0570\n",
      "第51代训练完成,历时1198.7408661842346秒\n",
      "epoch 51 mean training loss:0.8655\n",
      "epoch 51 mean training accuracy:0.4699\n",
      "epoch 51 mean training perplexity:5.7299\n",
      "epoch 51 mean val loss:1.1031\n",
      "epoch 51 mean val accuracy:0.3676 \n",
      "epoch 51 mean val perplexity:8.3832 \n",
      " \n",
      "train_batch:   0  loss:0.9524  accuracy:0.4522  perplexity:5.9980\n",
      "train_batch:  50  loss:0.8952  accuracy:0.4266  perplexity:6.4066\n",
      "val_batch:     0  loss:1.0772  accuracy:0.3773  perplexity:8.0081\n",
      "第52代训练完成,历时1222.2292866706848秒\n",
      "epoch 52 mean training loss:0.8612\n",
      "epoch 52 mean training accuracy:0.4709\n",
      "epoch 52 mean training perplexity:5.6818\n",
      "epoch 52 mean val loss:1.1175\n",
      "epoch 52 mean val accuracy:0.3664 \n",
      "epoch 52 mean val perplexity:8.5165 \n",
      " \n",
      "train_batch:   0  loss:0.8379  accuracy:0.5075  perplexity:5.0090\n",
      "train_batch:  50  loss:0.7000  accuracy:0.5487  perplexity:4.4210\n",
      "val_batch:     0  loss:0.9909  accuracy:0.4048  perplexity:7.2213\n",
      "第53代训练完成,历时1245.7303702831268秒\n",
      "epoch 53 mean training loss:0.8578\n",
      "epoch 53 mean training accuracy:0.4739\n",
      "epoch 53 mean training perplexity:5.6557\n",
      "epoch 53 mean val loss:1.1054\n",
      "epoch 53 mean val accuracy:0.3773 \n",
      "epoch 53 mean val perplexity:8.2254 \n",
      " \n",
      "train_batch:   0  loss:0.9186  accuracy:0.4704  perplexity:5.7027\n",
      "train_batch:  50  loss:0.8452  accuracy:0.4622  perplexity:5.5616\n",
      "val_batch:     0  loss:1.2586  accuracy:0.3312  perplexity:9.5171\n",
      "第54代训练完成,历时1269.2199759483337秒\n",
      "epoch 54 mean training loss:0.8565\n",
      "epoch 54 mean training accuracy:0.4735\n",
      "epoch 54 mean training perplexity:5.6255\n",
      "epoch 54 mean val loss:1.1229\n",
      "epoch 54 mean val accuracy:0.3687 \n",
      "epoch 54 mean val perplexity:8.4702 \n",
      " \n",
      "train_batch:   0  loss:0.8022  accuracy:0.5112  perplexity:5.0451\n",
      "train_batch:  50  loss:0.7525  accuracy:0.5046  perplexity:5.0793\n",
      "val_batch:     0  loss:1.1757  accuracy:0.3433  perplexity:9.3729\n",
      "第55代训练完成,历时1292.695806980133秒\n",
      "epoch 55 mean training loss:0.8524\n",
      "epoch 55 mean training accuracy:0.4778\n",
      "epoch 55 mean training perplexity:5.5784\n",
      "epoch 55 mean val loss:1.1248\n",
      "epoch 55 mean val accuracy:0.3720 \n",
      "epoch 55 mean val perplexity:8.4376 \n",
      " \n",
      "train_batch:   0  loss:0.9148  accuracy:0.4824  perplexity:5.3844\n",
      "train_batch:  50  loss:0.9353  accuracy:0.4539  perplexity:6.1502\n",
      "val_batch:     0  loss:0.9501  accuracy:0.4227  perplexity:6.9082\n",
      "第56代训练完成,历时1316.2708749771118秒\n",
      "epoch 56 mean training loss:0.8487\n",
      "epoch 56 mean training accuracy:0.4796\n",
      "epoch 56 mean training perplexity:5.5428\n",
      "epoch 56 mean val loss:1.1073\n",
      "epoch 56 mean val accuracy:0.3736 \n",
      "epoch 56 mean val perplexity:8.4159 \n",
      " \n",
      "train_batch:   0  loss:0.8186  accuracy:0.5081  perplexity:4.9309\n",
      "train_batch:  50  loss:0.8251  accuracy:0.4788  perplexity:5.3836\n",
      "val_batch:     0  loss:1.1683  accuracy:0.3291  perplexity:9.6495\n",
      "第57代训练完成,历时1339.7481215000153秒\n",
      "epoch 57 mean training loss:0.8469\n",
      "epoch 57 mean training accuracy:0.4797\n",
      "epoch 57 mean training perplexity:5.5158\n",
      "epoch 57 mean val loss:1.1037\n",
      "epoch 57 mean val accuracy:0.3699 \n",
      "epoch 57 mean val perplexity:8.4664 \n",
      " \n",
      "train_batch:   0  loss:0.8481  accuracy:0.4995  perplexity:5.1182\n",
      "train_batch:  50  loss:0.8464  accuracy:0.4715  perplexity:5.5264\n",
      "val_batch:     0  loss:1.0532  accuracy:0.4105  perplexity:7.3855\n",
      "第58代训练完成,历时1363.2436482906342秒\n",
      "epoch 58 mean training loss:0.8439\n",
      "epoch 58 mean training accuracy:0.4816\n",
      "epoch 58 mean training perplexity:5.4978\n",
      "epoch 58 mean val loss:1.1166\n",
      "epoch 58 mean val accuracy:0.3749 \n",
      "epoch 58 mean val perplexity:8.4541 \n",
      " \n",
      "train_batch:   0  loss:0.8076  accuracy:0.4644  perplexity:5.7249\n",
      "train_batch:  50  loss:0.9351  accuracy:0.4179  perplexity:6.5453\n",
      "val_batch:     0  loss:0.9777  accuracy:0.4271  perplexity:7.0876\n",
      "第59代训练完成,历时1386.7425756454468秒\n",
      "epoch 59 mean training loss:0.8408\n",
      "epoch 59 mean training accuracy:0.4837\n",
      "epoch 59 mean training perplexity:5.4561\n",
      "epoch 59 mean val loss:1.1157\n",
      "epoch 59 mean val accuracy:0.3749 \n",
      "epoch 59 mean val perplexity:8.4631 \n",
      " \n",
      "train_batch:   0  loss:0.8155  accuracy:0.4907  perplexity:5.3153\n",
      "train_batch:  50  loss:0.9113  accuracy:0.4880  perplexity:5.3144\n",
      "val_batch:     0  loss:1.1807  accuracy:0.3458  perplexity:9.3843\n",
      "第60代训练完成,历时1410.2473685741425秒\n",
      "epoch 60 mean training loss:0.8369\n",
      "epoch 60 mean training accuracy:0.4862\n",
      "epoch 60 mean training perplexity:5.4223\n",
      "epoch 60 mean val loss:1.0959\n",
      "epoch 60 mean val accuracy:0.3772 \n",
      "epoch 60 mean val perplexity:8.2672 \n",
      " \n",
      "train_batch:   0  loss:0.8852  accuracy:0.4618  perplexity:5.7072\n",
      "train_batch:  50  loss:0.7542  accuracy:0.5014  perplexity:5.1351\n",
      "val_batch:     0  loss:1.2041  accuracy:0.3501  perplexity:8.8962\n",
      "第61代训练完成,历时1433.7389585971832秒\n",
      "epoch 61 mean training loss:0.8373\n",
      "epoch 61 mean training accuracy:0.4852\n",
      "epoch 61 mean training perplexity:5.4127\n",
      "epoch 61 mean val loss:1.1017\n",
      "epoch 61 mean val accuracy:0.3821 \n",
      "epoch 61 mean val perplexity:8.2760 \n",
      " \n",
      "train_batch:   0  loss:0.7663  accuracy:0.5285  perplexity:4.9086\n",
      "train_batch:  50  loss:0.8232  accuracy:0.5069  perplexity:4.9750\n",
      "val_batch:     0  loss:0.9683  accuracy:0.3650  perplexity:8.3986\n",
      "第62代训练完成,历时1457.1944994926453秒\n",
      "epoch 62 mean training loss:0.8348\n",
      "epoch 62 mean training accuracy:0.4883\n",
      "epoch 62 mean training perplexity:5.3720\n",
      "epoch 62 mean val loss:1.1387\n",
      "epoch 62 mean val accuracy:0.3673 \n",
      "epoch 62 mean val perplexity:8.6225 \n",
      " \n",
      "train_batch:   0  loss:0.7768  accuracy:0.4666  perplexity:5.6622\n",
      "val_batch:     0  loss:1.0794  accuracy:0.3908  perplexity:7.8628\n",
      "第63代训练完成,历时1480.6845905780792秒\n",
      "epoch 63 mean training loss:0.8318\n",
      "epoch 63 mean training accuracy:0.4891\n",
      "epoch 63 mean training perplexity:5.3617\n",
      "epoch 63 mean val loss:1.1043\n",
      "epoch 63 mean val accuracy:0.3762 \n",
      "epoch 63 mean val perplexity:8.4023 \n",
      " \n",
      "train_batch:   0  loss:0.8364  accuracy:0.4906  perplexity:5.3594\n",
      "train_batch:  50  loss:0.7881  accuracy:0.4857  perplexity:5.2546\n",
      "val_batch:     0  loss:1.1611  accuracy:0.3429  perplexity:9.2404\n",
      "第64代训练完成,历时1504.1677706241608秒\n",
      "epoch 64 mean training loss:0.8298\n",
      "epoch 64 mean training accuracy:0.4900\n",
      "epoch 64 mean training perplexity:5.3474\n",
      "epoch 64 mean val loss:1.1152\n",
      "epoch 64 mean val accuracy:0.3796 \n",
      "epoch 64 mean val perplexity:8.3894 \n",
      " \n",
      "train_batch:   0  loss:0.9345  accuracy:0.5004  perplexity:5.1016\n",
      "train_batch:  50  loss:0.7818  accuracy:0.5040  perplexity:5.0546\n",
      "val_batch:     0  loss:1.0305  accuracy:0.3855  perplexity:8.0726\n",
      "第65代训练完成,历时1527.6559300422668秒\n",
      "epoch 65 mean training loss:0.8273\n",
      "epoch 65 mean training accuracy:0.4926\n",
      "epoch 65 mean training perplexity:5.3223\n",
      "epoch 65 mean val loss:1.1021\n",
      "epoch 65 mean val accuracy:0.3793 \n",
      "epoch 65 mean val perplexity:8.3510 \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch:   0  loss:0.8394  accuracy:0.5025  perplexity:5.2963\n",
      "train_batch:  50  loss:0.8293  accuracy:0.4967  perplexity:5.3396\n",
      "第66代训练完成,历时1551.1488945484161秒\n",
      "epoch 66 mean training loss:0.8243\n",
      "epoch 66 mean training accuracy:0.4938\n",
      "epoch 66 mean training perplexity:5.2845\n",
      "epoch 66 mean val loss:1.1232\n",
      "epoch 66 mean val accuracy:0.3704 \n",
      "epoch 66 mean val perplexity:8.4698 \n",
      " \n",
      "train_batch:   0  loss:0.9469  accuracy:0.4469  perplexity:6.0518\n",
      "train_batch:  50  loss:0.8694  accuracy:0.4613  perplexity:5.8648\n",
      "val_batch:     0  loss:1.2907  accuracy:0.3510  perplexity:9.5989\n",
      "第67代训练完成,历时1574.6456258296967秒\n",
      "epoch 67 mean training loss:0.8238\n",
      "epoch 67 mean training accuracy:0.4928\n",
      "epoch 67 mean training perplexity:5.2689\n",
      "epoch 67 mean val loss:1.1111\n",
      "epoch 67 mean val accuracy:0.3779 \n",
      "epoch 67 mean val perplexity:8.3641 \n",
      " \n",
      "train_batch:   0  loss:0.8742  accuracy:0.4690  perplexity:5.7445\n",
      "train_batch:  50  loss:0.6869  accuracy:0.5280  perplexity:4.6488\n",
      "val_batch:     0  loss:1.0619  accuracy:0.3725  perplexity:8.6243\n",
      "第68代训练完成,历时1598.146725177765秒\n",
      "epoch 68 mean training loss:0.8226\n",
      "epoch 68 mean training accuracy:0.4946\n",
      "epoch 68 mean training perplexity:5.2752\n",
      "epoch 68 mean val loss:1.1068\n",
      "epoch 68 mean val accuracy:0.3813 \n",
      "epoch 68 mean val perplexity:8.2714 \n",
      " \n",
      "train_batch:   0  loss:0.8907  accuracy:0.4786  perplexity:5.5222\n",
      "train_batch:  50  loss:0.8395  accuracy:0.4643  perplexity:5.6456\n",
      "val_batch:     0  loss:1.2294  accuracy:0.3491  perplexity:9.1327\n",
      "train_batch:  50  loss:0.8921  accuracy:0.4949  perplexity:5.4234\n",
      "val_batch:     0  loss:0.9935  accuracy:0.4038  perplexity:7.4411\n",
      "第70代训练完成,历时1645.164824962616秒\n",
      "epoch 70 mean training loss:0.8164\n",
      "epoch 70 mean training accuracy:0.4975\n",
      "epoch 70 mean training perplexity:5.2025\n",
      "epoch 70 mean val loss:1.1015\n",
      "epoch 70 mean val accuracy:0.3811 \n",
      "epoch 70 mean val perplexity:8.2924 \n",
      " \n",
      "train_batch:   0  loss:0.8912  accuracy:0.4784  perplexity:5.5524\n",
      "train_batch:  50  loss:0.8464  accuracy:0.4880  perplexity:5.3922\n",
      "val_batch:     0  loss:1.2874  accuracy:0.3589  perplexity:9.5230\n",
      "第71代训练完成,历时1668.7296345233917秒\n",
      "epoch 71 mean training loss:0.8164\n",
      "epoch 71 mean training accuracy:0.4979\n",
      "epoch 71 mean training perplexity:5.2013\n",
      "epoch 71 mean val loss:1.1176\n",
      "epoch 71 mean val accuracy:0.3774 \n",
      "epoch 71 mean val perplexity:8.3843 \n",
      " \n",
      "train_batch:   0  loss:0.8396  accuracy:0.4715  perplexity:5.4829\n",
      "val_batch:     0  loss:1.0185  accuracy:0.4314  perplexity:7.0388\n",
      "第72代训练完成,历时1692.219945192337秒\n",
      "epoch 72 mean training loss:0.8142\n",
      "epoch 72 mean training accuracy:0.5014\n",
      "epoch 72 mean training perplexity:5.1649\n",
      "epoch 72 mean val loss:1.1182\n",
      "epoch 72 mean val accuracy:0.3781 \n",
      "epoch 72 mean val perplexity:8.4935 \n",
      " \n",
      "train_batch:   0  loss:0.7704  accuracy:0.5435  perplexity:4.3100\n",
      "train_batch:  50  loss:0.8304  accuracy:0.5136  perplexity:4.9542\n",
      "val_batch:     0  loss:1.2853  accuracy:0.3604  perplexity:9.9972\n",
      "第73代训练完成,历时1715.7337086200714秒\n",
      "epoch 73 mean training loss:0.8111\n",
      "epoch 73 mean training accuracy:0.5005\n",
      "epoch 73 mean training perplexity:5.1482\n",
      "epoch 73 mean val loss:1.1078\n",
      "epoch 73 mean val accuracy:0.3783 \n",
      "epoch 73 mean val perplexity:8.4701 \n",
      " \n",
      "train_batch:   0  loss:0.7876  accuracy:0.4916  perplexity:5.3751\n",
      "train_batch:  50  loss:0.7996  accuracy:0.5413  perplexity:4.5131\n",
      "val_batch:     0  loss:1.1841  accuracy:0.3763  perplexity:8.4741\n",
      "第74代训练完成,历时1739.2319796085358秒\n",
      "epoch 74 mean training loss:0.8108\n",
      "epoch 74 mean training accuracy:0.5023\n",
      "epoch 74 mean training perplexity:5.1286\n",
      "epoch 74 mean val loss:1.1205\n",
      "epoch 74 mean val accuracy:0.3768 \n",
      "epoch 74 mean val perplexity:8.4557 \n",
      " \n",
      "train_batch:   0  loss:0.8843  accuracy:0.4745  perplexity:5.6158\n",
      "train_batch:  50  loss:0.6901  accuracy:0.5163  perplexity:4.7101\n",
      "val_batch:     0  loss:1.2130  accuracy:0.3748  perplexity:8.5689\n",
      "第75代训练完成,历时1762.7574636936188秒\n",
      "epoch 75 mean training loss:0.8068\n",
      "epoch 75 mean training accuracy:0.5036\n",
      "epoch 75 mean training perplexity:5.1056\n",
      "epoch 75 mean val loss:1.0982\n",
      "epoch 75 mean val accuracy:0.3807 \n",
      "epoch 75 mean val perplexity:8.3121 \n",
      " \n",
      "train_batch:   0  loss:0.8066  accuracy:0.4946  perplexity:5.1747\n",
      "train_batch:  50  loss:0.7861  accuracy:0.5173  perplexity:4.8828\n",
      "val_batch:     0  loss:1.1652  accuracy:0.3472  perplexity:9.3855\n",
      "第76代训练完成,历时1786.2575097084045秒\n",
      "epoch 76 mean training loss:0.8069\n",
      "epoch 76 mean training accuracy:0.5034\n",
      "epoch 76 mean training perplexity:5.1029\n",
      "epoch 76 mean val loss:1.1043\n",
      "epoch 76 mean val accuracy:0.3797 \n",
      "epoch 76 mean val perplexity:8.2418 \n",
      " \n",
      "train_batch:   0  loss:0.8325  accuracy:0.5020  perplexity:5.1751\n",
      "train_batch:  50  loss:0.8767  accuracy:0.4869  perplexity:5.3796\n",
      "val_batch:     0  loss:1.2037  accuracy:0.3688  perplexity:8.7294\n",
      "第77代训练完成,历时1809.747303724289秒\n",
      "epoch 77 mean training loss:0.8059\n",
      "epoch 77 mean training accuracy:0.5047\n",
      "epoch 77 mean training perplexity:5.1004\n",
      "epoch 77 mean val loss:1.1344\n",
      "epoch 77 mean val accuracy:0.3770 \n",
      "epoch 77 mean val perplexity:8.5975 \n",
      " \n",
      "train_batch:   0  loss:0.7617  accuracy:0.5123  perplexity:4.8294\n",
      "train_batch:  50  loss:0.8036  accuracy:0.5265  perplexity:4.8522\n",
      "val_batch:     0  loss:1.1671  accuracy:0.3612  perplexity:8.8794\n",
      "第78代训练完成,历时1833.2596652507782秒\n",
      "epoch 78 mean training loss:0.8060\n",
      "epoch 78 mean training accuracy:0.5035\n",
      "epoch 78 mean training perplexity:5.0994\n",
      "epoch 78 mean val loss:1.0851\n",
      "epoch 78 mean val accuracy:0.3858 \n",
      "epoch 78 mean val perplexity:8.1349 \n",
      " \n",
      "train_batch:   0  loss:0.7839  accuracy:0.5034  perplexity:5.0775\n",
      "train_batch:  50  loss:0.9039  accuracy:0.4459  perplexity:5.8731\n",
      "val_batch:     0  loss:1.0596  accuracy:0.4086  perplexity:7.9336\n",
      "第79代训练完成,历时1856.7919781208038秒\n",
      "epoch 79 mean training loss:0.8016\n",
      "epoch 79 mean training accuracy:0.5075\n",
      "epoch 79 mean training perplexity:5.0481\n",
      "epoch 79 mean val loss:1.0840\n",
      "epoch 79 mean val accuracy:0.3865 \n",
      "epoch 79 mean val perplexity:8.1206 \n",
      " \n",
      "train_batch:   0  loss:0.7061  accuracy:0.5605  perplexity:4.3854\n",
      "train_batch:  50  loss:0.7490  accuracy:0.5358  perplexity:4.5765\n",
      "val_batch:     0  loss:1.2121  accuracy:0.3457  perplexity:9.5657\n",
      "第80代训练完成,历时1880.2837743759155秒\n",
      "epoch 80 mean training loss:0.8015\n",
      "epoch 80 mean training accuracy:0.5066\n",
      "epoch 80 mean training perplexity:5.0511\n",
      "epoch 80 mean val loss:1.1136\n",
      "epoch 80 mean val accuracy:0.3830 \n",
      "epoch 80 mean val perplexity:8.2954 \n",
      " \n",
      "train_batch:   0  loss:0.7109  accuracy:0.5171  perplexity:4.8260\n",
      "train_batch:  50  loss:0.7530  accuracy:0.5267  perplexity:4.6232\n",
      "val_batch:     0  loss:1.0632  accuracy:0.3758  perplexity:8.1901\n",
      "第81代训练完成,历时1903.7965989112854秒\n",
      "epoch 81 mean training loss:0.7991\n",
      "epoch 81 mean training accuracy:0.5072\n",
      "epoch 81 mean training perplexity:5.0231\n",
      "epoch 81 mean val loss:1.0992\n",
      "epoch 81 mean val accuracy:0.3805 \n",
      "epoch 81 mean val perplexity:8.2973 \n",
      " \n",
      "train_batch:   0  loss:0.8543  accuracy:0.5012  perplexity:5.1028\n",
      "train_batch:  50  loss:0.9064  accuracy:0.4722  perplexity:5.5705\n",
      "第82代训练完成,历时1927.2548644542694秒\n",
      "epoch 82 mean training loss:0.8001\n",
      "epoch 82 mean training accuracy:0.5105\n",
      "epoch 82 mean training perplexity:5.0127\n",
      "epoch 82 mean val loss:1.1085\n",
      "epoch 82 mean val accuracy:0.3812 \n",
      "epoch 82 mean val perplexity:8.4167 \n",
      " \n",
      "train_batch:   0  loss:0.8157  accuracy:0.4976  perplexity:5.4287\n",
      "train_batch:  50  loss:0.7544  accuracy:0.5056  perplexity:4.9790\n",
      "第83代训练完成,历时1950.747316122055秒\n",
      "epoch 83 mean training loss:0.7974\n",
      "epoch 83 mean training accuracy:0.5086\n",
      "epoch 83 mean training perplexity:5.0187\n",
      "epoch 83 mean val loss:1.1203\n",
      "epoch 83 mean val accuracy:0.3761 \n",
      "epoch 83 mean val perplexity:8.5722 \n",
      " \n",
      "train_batch:   0  loss:0.7656  accuracy:0.5256  perplexity:4.7927\n",
      "train_batch:  50  loss:0.7300  accuracy:0.5503  perplexity:4.4984\n",
      "val_batch:     0  loss:0.8669  accuracy:0.4663  perplexity:6.1560\n",
      "第84代训练完成,历时1974.2031004428864秒\n",
      "epoch 84 mean training loss:0.7988\n",
      "epoch 84 mean training accuracy:0.5096\n",
      "epoch 84 mean training perplexity:5.0139\n",
      "epoch 84 mean val loss:1.1165\n",
      "epoch 84 mean val accuracy:0.3836 \n",
      "epoch 84 mean val perplexity:8.3363 \n",
      " \n",
      "train_batch:   0  loss:0.8788  accuracy:0.4925  perplexity:5.1583\n",
      "train_batch:  50  loss:0.9722  accuracy:0.4479  perplexity:6.3748\n",
      "val_batch:     0  loss:1.1162  accuracy:0.3984  perplexity:7.8458\n",
      "第85代训练完成,历时1997.7691338062286秒\n",
      "epoch 85 mean training loss:0.7955\n",
      "epoch 85 mean training accuracy:0.5109\n",
      "epoch 85 mean training perplexity:4.9969\n",
      "epoch 85 mean val loss:1.1071\n",
      "epoch 85 mean val accuracy:0.3837 \n",
      "epoch 85 mean val perplexity:8.2692 \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch:   0  loss:0.8217  accuracy:0.5040  perplexity:5.0919\n",
      "train_batch:  50  loss:0.8185  accuracy:0.4987  perplexity:5.1080\n",
      "val_batch:     0  loss:1.2195  accuracy:0.3356  perplexity:9.8599\n",
      "第86代训练完成,历时2021.2709577083588秒\n",
      "epoch 86 mean training loss:0.7954\n",
      "epoch 86 mean training accuracy:0.5100\n",
      "epoch 86 mean training perplexity:4.9948\n",
      "epoch 86 mean val loss:1.1181\n",
      "epoch 86 mean val accuracy:0.3795 \n",
      "epoch 86 mean val perplexity:8.5176 \n",
      " \n",
      "train_batch:   0  loss:0.9119  accuracy:0.4537  perplexity:5.9325\n",
      "train_batch:  50  loss:0.7770  accuracy:0.5145  perplexity:4.9067\n",
      "val_batch:     0  loss:1.1981  accuracy:0.3568  perplexity:9.1928\n",
      "第87代训练完成,历时2044.7435276508331秒\n",
      "epoch 87 mean training loss:0.7953\n",
      "epoch 87 mean training accuracy:0.5108\n",
      "epoch 87 mean training perplexity:4.9786\n",
      "epoch 87 mean val loss:1.1252\n",
      "epoch 87 mean val accuracy:0.3770 \n",
      "epoch 87 mean val perplexity:8.6112 \n",
      " \n",
      "train_batch:   0  loss:0.9115  accuracy:0.4629  perplexity:5.8637\n",
      "train_batch:  50  loss:0.7547  accuracy:0.5139  perplexity:4.8961\n",
      "val_batch:     0  loss:1.1436  accuracy:0.3601  perplexity:9.2703\n",
      "第88代训练完成,历时2068.2308440208435秒\n",
      "epoch 88 mean training loss:0.7936\n",
      "epoch 88 mean training accuracy:0.5118\n",
      "epoch 88 mean training perplexity:4.9602\n",
      "epoch 88 mean val loss:1.1114\n",
      "epoch 88 mean val accuracy:0.3823 \n",
      "epoch 88 mean val perplexity:8.4028 \n",
      " \n",
      "train_batch:   0  loss:0.9084  accuracy:0.4570  perplexity:5.8793\n",
      "train_batch:  50  loss:0.8067  accuracy:0.4869  perplexity:5.3156\n",
      "val_batch:     0  loss:0.9900  accuracy:0.4041  perplexity:7.7315\n",
      "第89代训练完成,历时2091.7357296943665秒\n",
      "epoch 89 mean training loss:0.7914\n",
      "epoch 89 mean training accuracy:0.5132\n",
      "epoch 89 mean training perplexity:4.9476\n",
      "epoch 89 mean val loss:1.1122\n",
      "epoch 89 mean val accuracy:0.3821 \n",
      "epoch 89 mean val perplexity:8.2933 \n",
      " \n",
      "train_batch:   0  loss:0.6858  accuracy:0.5157  perplexity:4.7913\n",
      "train_batch:  50  loss:0.7683  accuracy:0.5131  perplexity:4.8103\n",
      "val_batch:     0  loss:1.0871  accuracy:0.3967  perplexity:8.1176\n",
      "第90代训练完成,历时2115.233165740967秒\n",
      "epoch 90 mean training loss:0.7908\n",
      "epoch 90 mean training accuracy:0.5128\n",
      "epoch 90 mean training perplexity:4.9493\n",
      "epoch 90 mean val loss:1.1088\n",
      "epoch 90 mean val accuracy:0.3875 \n",
      "epoch 90 mean val perplexity:8.3289 \n",
      " \n",
      "train_batch:   0  loss:0.7585  accuracy:0.5523  perplexity:4.3062\n",
      "train_batch:  50  loss:0.7368  accuracy:0.5638  perplexity:4.3134\n",
      "val_batch:     0  loss:0.9260  accuracy:0.4486  perplexity:6.6182\n",
      "第91代训练完成,历时2138.7316060066223秒\n",
      "epoch 91 mean training loss:0.7903\n",
      "epoch 91 mean training accuracy:0.5147\n",
      "epoch 91 mean training perplexity:4.9322\n",
      "epoch 91 mean val loss:1.1079\n",
      "epoch 91 mean val accuracy:0.3812 \n",
      "epoch 91 mean val perplexity:8.3169 \n",
      " \n",
      "train_batch:   0  loss:0.7488  accuracy:0.5430  perplexity:4.4411\n",
      "train_batch:  50  loss:0.8313  accuracy:0.5171  perplexity:5.0396\n",
      "val_batch:     0  loss:1.1144  accuracy:0.3646  perplexity:8.6917\n",
      "第92代训练完成,历时2162.1931545734406秒\n",
      "epoch 92 mean training loss:0.7929\n",
      "epoch 92 mean training accuracy:0.5133\n",
      "epoch 92 mean training perplexity:4.9476\n",
      "epoch 92 mean val loss:1.0996\n",
      "epoch 92 mean val accuracy:0.3866 \n",
      "epoch 92 mean val perplexity:8.2449 \n",
      " \n",
      "train_batch:   0  loss:0.7942  accuracy:0.5043  perplexity:4.9164\n",
      "train_batch:  50  loss:0.7783  accuracy:0.5081  perplexity:5.0237\n",
      "val_batch:     0  loss:1.1962  accuracy:0.3564  perplexity:9.3689\n",
      "第93代训练完成,历时2185.6510379314423秒\n",
      "epoch 93 mean training loss:0.7927\n",
      "epoch 93 mean training accuracy:0.5134\n",
      "epoch 93 mean training perplexity:4.9457\n",
      "epoch 93 mean val loss:1.1233\n",
      "epoch 93 mean val accuracy:0.3809 \n",
      "epoch 93 mean val perplexity:8.4694 \n",
      " \n",
      "train_batch:   0  loss:0.6971  accuracy:0.5502  perplexity:4.3695\n",
      "train_batch:  50  loss:0.8021  accuracy:0.5146  perplexity:4.9466\n",
      "val_batch:     0  loss:1.1480  accuracy:0.4032  perplexity:8.2904\n",
      "第94代训练完成,历时2209.1627938747406秒\n",
      "epoch 94 mean training loss:0.7892\n",
      "epoch 94 mean training accuracy:0.5139\n",
      "epoch 94 mean training perplexity:4.9406\n",
      "epoch 94 mean val loss:1.1070\n",
      "epoch 94 mean val accuracy:0.3872 \n",
      "epoch 94 mean val perplexity:8.3087 \n",
      " \n",
      "train_batch:   0  loss:0.8128  accuracy:0.5085  perplexity:5.0621\n",
      "train_batch:  50  loss:0.8882  accuracy:0.4833  perplexity:5.5057\n",
      "val_batch:     0  loss:1.0101  accuracy:0.4385  perplexity:6.8738\n",
      "第95代训练完成,历时2232.6034030914307秒\n",
      "epoch 95 mean training loss:0.7913\n",
      "epoch 95 mean training accuracy:0.5138\n",
      "epoch 95 mean training perplexity:4.9388\n",
      "epoch 95 mean val loss:1.1063\n",
      "epoch 95 mean val accuracy:0.3836 \n",
      "epoch 95 mean val perplexity:8.3396 \n",
      " \n",
      "train_batch:   0  loss:0.6684  accuracy:0.5601  perplexity:4.1465\n",
      "train_batch:  50  loss:0.8497  accuracy:0.5161  perplexity:4.9356\n",
      "val_batch:     0  loss:1.0538  accuracy:0.4074  perplexity:7.5615\n",
      "第96代训练完成,历时2256.115439891815秒\n",
      "epoch 96 mean training loss:0.7889\n",
      "epoch 96 mean training accuracy:0.5147\n",
      "epoch 96 mean training perplexity:4.9379\n",
      "epoch 96 mean val loss:1.1209\n",
      "epoch 96 mean val accuracy:0.3823 \n",
      "epoch 96 mean val perplexity:8.4411 \n",
      " \n",
      "train_batch:   0  loss:0.7401  accuracy:0.5220  perplexity:4.7155\n",
      "train_batch:  50  loss:0.9124  accuracy:0.4186  perplexity:6.4447\n",
      "val_batch:     0  loss:1.1450  accuracy:0.3705  perplexity:8.5999\n",
      "第97代训练完成,历时2279.5999035835266秒\n",
      "epoch 97 mean training loss:0.7898\n",
      "epoch 97 mean training accuracy:0.5152\n",
      "epoch 97 mean training perplexity:4.9334\n",
      "epoch 97 mean val loss:1.0964\n",
      "epoch 97 mean val accuracy:0.3845 \n",
      "epoch 97 mean val perplexity:8.2256 \n",
      " \n",
      "train_batch:   0  loss:0.8105  accuracy:0.5320  perplexity:4.6893\n",
      "train_batch:  50  loss:0.5859  accuracy:0.6086  perplexity:3.7177\n",
      "val_batch:     0  loss:0.9662  accuracy:0.4292  perplexity:7.1860\n",
      "第98代训练完成,历时2303.1046240329742秒\n",
      "epoch 98 mean training loss:0.7883\n",
      "epoch 98 mean training accuracy:0.5154\n",
      "epoch 98 mean training perplexity:4.9181\n",
      "epoch 98 mean val loss:1.1190\n",
      "epoch 98 mean val accuracy:0.3810 \n",
      "epoch 98 mean val perplexity:8.4208 \n",
      " \n",
      "train_batch:   0  loss:0.7432  accuracy:0.5464  perplexity:4.2234\n",
      "train_batch:  50  loss:0.7864  accuracy:0.5095  perplexity:4.9492\n",
      "val_batch:     0  loss:1.0060  accuracy:0.4089  perplexity:7.7414\n",
      "第99代训练完成,历时2326.5910136699677秒\n",
      "epoch 99 mean training loss:0.7886\n",
      "epoch 99 mean training accuracy:0.5145\n",
      "epoch 99 mean training perplexity:4.9207\n",
      "epoch 99 mean val loss:1.1139\n",
      "epoch 99 mean val accuracy:0.3796 \n",
      "epoch 99 mean val perplexity:8.3923 \n",
      " \n",
      "train_batch:   0  loss:0.7614  accuracy:0.5088  perplexity:4.9352\n",
      "train_batch:  50  loss:0.7625  accuracy:0.5204  perplexity:4.7376\n",
      "val_batch:     0  loss:1.0189  accuracy:0.3908  perplexity:7.9607\n",
      "第100代训练完成,历时2350.0709817409515秒\n",
      "epoch 100 mean training loss:0.7878\n",
      "epoch 100 mean training accuracy:0.5160\n",
      "epoch 100 mean training perplexity:4.9117\n",
      "epoch 100 mean val loss:1.1194\n",
      "epoch 100 mean val accuracy:0.3884 \n",
      "epoch 100 mean val perplexity:8.2960 \n",
      " \n",
      "训练结束,训练时长： 2350.071156024933 秒\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aead84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存模型\n",
    "\n",
    "# model = model.to('cpu')\n",
    "\n",
    "# if mode == 'pretrain':\n",
    "#     model.save_pretrained('./save_model/pretrain_model/pretrained-GPT-10-64raw-20epochs/')  # when pretrain model\n",
    "# elif mode == 'finetune':\n",
    "#     torch.save(model, './save_model/finetune-model/finetune_with_AMPbert_data/finetune-10-48-GPT-'+str(epochs)+'epochs')  # finetune model\n",
    "# else:\n",
    "#     pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e8cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 困惑度趋势图\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_dir = '/home/xms/AMP-master/generate_file/train_acc_loss/'\n",
    "\n",
    "x1 = [(x+1) for x in range(len(train_pp_list))]\n",
    "x2 = [(x+1) for x in range(len(val_pp_list))]\n",
    "y1 = train_pp_list\n",
    "y2 = val_pp_list\n",
    "\n",
    "plt.plot(x1, y1, label=\"AMP training perplexity\")\n",
    "plt.plot(x1, y2, label=\"AMP val_perplexity\")\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('perplexity')\n",
    "plt.title('AMP train perplexity show')\n",
    "plt.legend()\n",
    "plt.savefig(save_dir+str(epochs)+'_AMP train perplexity show')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2644c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 结果作图\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# x1 = [(x+1) for x in range(len(train_loss_list))]\n",
    "# x2 = [(x+1) for x in range(len(val_acc_list))]\n",
    "# y1 = train_loss_list\n",
    "# y2 = train_acc_list\n",
    "# y3 = val_loss_list\n",
    "# y4 = val_acc_list\n",
    "\n",
    "# plt.plot(x1, y1, label=\"AMP training loss\")\n",
    "# plt.plot(x1, y3, label=\"AMP val_loss\")\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('AMP train losses show')\n",
    "# plt.legend()\n",
    "# if mode == 'pretrain':\n",
    "#     plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/pretrain_result/'+\n",
    "#                 mode+'10-48washed-'+str(epochs)+'epochs_loss.jpg')\n",
    "# elif mode == 'finetune':\n",
    "#     plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/finetune_result/'+\n",
    "#                 mode+'10-48washed-'+str(epochs)+'epochs_loss.jpg')\n",
    "# else:\n",
    "#     pass\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(x2, y2, label=\"AMP train_acc curse\")\n",
    "# plt.plot(x2, y4, label=\"AMP val_acc curse\")\n",
    "# plt.xlabel('step')\n",
    "# plt.ylabel('acc')\n",
    "# plt.title('AMP val_acc show')\n",
    "# plt.legend()\n",
    "# if mode == 'pretrain':\n",
    "#     plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/pretrain_result/'+\n",
    "#                 mode+'10-48washed-'+str(epochs)+'epochs_accuracy.jpg')\n",
    "# elif mode == 'finetune':\n",
    "#     plt.savefig('/xms/AMP-master/generate_file/train_graphical_result-2023/finetune_result/'+\n",
    "#                 mode+'10-48washed-'+str(epochs)+'epochs_accuracy.jpg')\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Perplexity\n",
    "preds = torch.rand(2, 8, 5, generator=torch.manual_seed(22))\n",
    "print(preds)\n",
    "target = torch.randint(5, (2, 8), generator=torch.manual_seed(22))\n",
    "print(target)\n",
    "target[0, 6:] = -100\n",
    "perp = Perplexity(ignore_index=-100)\n",
    "perp(preds, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b999515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy(task=\"multiclass\",num_classes=23,ignore_index=23)\n",
    "\n",
    "a = torch.tensor([[1,2],[12,23]])\n",
    "b = torch.tensor([[2,2],[12,23]])\n",
    "print(accuracy(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f3da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
